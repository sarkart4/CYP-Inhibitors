{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt for CYP2D6 dataset\n",
    "I used cyp2d6_union_trainset_base_smiles.csv from MoDaC old data.\n",
    "Goal:Generate models with RF, NN, XGBoost with different parameter setting and select best model based on valid_r2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Done.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from atomsci.ddm.pipeline import model_pipeline as mp\n",
    "from atomsci.ddm.pipeline import parameter_parser as parse\n",
    "from atomsci.ddm.pipeline import predict_from_model as pfm \n",
    "from atomsci.ddm.pipeline import compare_models as cm \n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "pal = sns.color_palette()\n",
    "\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', 150)\n",
    "\n",
    "print(\"Imports Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='CYP2D6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/projects/ATOM/sarkart4/Data/'+target+'-ampl-1.1.0_old/'\n",
    "outdir = '/mnt/projects/ATOM/sarkart4/Data/HPO_models_'+target+'_old/'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_rdkit_smiles</th>\n",
       "      <th>compound_id</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>relation</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCCOc1ccn2c(-c3ccc4cccc(OC5CCNCC5)c4n3)cnc2c1</td>\n",
       "      <td>CHEMBL3109340</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN1CCC[C@@H](CC2c3ccccc3Sc3ccccc32)C1</td>\n",
       "      <td>MJFJKKXQDNNUJF-HNNXBMFYNA-N</td>\n",
       "      <td>6.50004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                base_rdkit_smiles  \\\n",
       "0  COCCOc1ccn2c(-c3ccc4cccc(OC5CCNCC5)c4n3)cnc2c1   \n",
       "1           CN1CCC[C@@H](CC2c3ccccc3Sc3ccccc32)C1   \n",
       "\n",
       "                   compound_id    pIC50 relation  active  \n",
       "0                CHEMBL3109340  5.00000      NaN       1  \n",
       "1  MJFJKKXQDNNUJF-HNNXBMFYNA-N  6.50004      NaN       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_file = data_dir + \"cyp2d6_union_testset_base_smiles.csv\"\n",
    "data_file = data_dir + target.lower()+\"_union_trainset_base_smiles.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate SMILES: 0 \tDuplicate compound IDs: 0 \tDuplicate indices: 0 \tNA SMILES: 0\n",
      "Shape: (10445, 5)\n",
      "CYP2D6 actives: 6982\n",
      "CYP2D6 inactives: 3463\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate SMILES:\",data.duplicated(subset=\"base_rdkit_smiles\").sum(), \"\\tDuplicate compound IDs:\",data.duplicated(subset=\"compound_id\").sum(), \"\\tDuplicate indices:\",data.index.duplicated().sum(), \"\\tNA SMILES:\",data.base_rdkit_smiles.isna().sum())\n",
    "print(\"Shape:\", data.shape)\n",
    "print('CYP2D6 actives:', data.active.sum())\n",
    "print('CYP2D6 inactives:', len(data)-data.active.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4dc24a89-e3c9-4c91-b8b1-6244f5a76132',\n",
       " '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save split uuids for future reference\n",
    "# all are mordread_filtered\n",
    "# /home/sarkart4/MoDaC/NCI_DOE_Archive/ATOM/Safety_Screen_Targets/CYP2D6-ampl-1.1.0/cyp2d6_union_trainset_base_smiles_train_valid_test_scaffold_c8c36365-b294-41a4-983a-57879bbde0c0.csv\n",
    "# /home/sarkart4/MoDaC/NCI_DOE_Archive/ATOM/Safety_Screen_Targets/CYP2D6-ampl-1.1.0/cyp2d6_union_trainset_base_smiles_train_valid_test_scaffold_4cb49d5e-1882-474e-ae0b-781d77a4738a.csv\n",
    "# Dataset split table saved to /mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0/cyp2d6_union_trainset_base_smiles_train_valid_test_scaffold_5fdd8051-5b67-4a13-a768-a8a702d0182b.csv\n",
    "\n",
    "#CYP2D6_old FRCE\n",
    "#Dataset split table saved to /mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles_train_valid_test_scaffold_c391ef72-9cd5-4bb7-a88e-9c55be5012a9.csv\n",
    "#split_uuid = 'c391ef72-9cd5-4bb7-a88e-9c55be5012a9' # scaffold, ecfp\n",
    "split_uuid =  '4dc24a89-e3c9-4c91-b8b1-6244f5a76132'# scaffold, graphconv\n",
    "#split_uuid =  '621c5873-bd9e-400e-a379-fd94996d547a' # scaffold, rdkit_raw\n",
    "#split_uuid = 'c517f69d-dd98-46c9-a9ae-94e6488149fb' # scaffold,mord\n",
    "[split_uuid,data_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf = pd.read_csv(data_dir+\"scaled_descriptors/cyp2d6_union_trainset_base_smiles_with_mordred_filtered_descriptors.csv\")\n",
    "#mf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  #  \"hyperparam\": \"True\",\n",
    "    \"search_type\" : \"user_specified\",\n",
    "    \"save_results\": \"False\",\n",
    "    \"collection_name\": \"CYP2D6\",\n",
    "    \"rerun\": \"False\",\n",
    "    \"dataset_key\" : data_file,\n",
    "    \"datastore\": \"False\",\n",
    "    \"response_cols\" : \"pIC50\", \n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\" : \"base_rdkit_smiles\",\n",
    "    \"result_dir\": outdir, \n",
    "    \"split_only\": \"False\",\n",
    "    \"previously_split\": \"True\",\n",
    "    \"split_uuid\": split_uuid,\n",
    "    \"splitter\": \"scaffold\",\n",
    "    #\"split_valid_frac\": \"0.15\",\n",
    "    #\"split_test_frac\": \"0.002\",\n",
    "    \"prediction_type\": \"regression\",\n",
    "    \"transformers\": \"True\",\n",
    "    \"featurizer\": \"computed_descriptors\",\n",
    "    \"descriptor_type\": \"rdkit_raw\", \n",
    "    \"max_epochs\": \"100\",\n",
    "    \"model_type\" :\"RF\",\n",
    "    \"uncertainty\": \"True\",\n",
    "    \"verbose\": \"True\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/dbfc8da7-0711-4811-923a-08245daa1bb6/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.822, validation r2_score = 0.167, test r2_score = -0.040\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_dbfc8da7-0711-4811-923a-08245daa1bb6.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.16726828648589243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9d0c9672-2d33-48f6-83fb-29f1244c1289/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.797, validation r2_score = 0.174, test r2_score = 0.051\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9d0c9672-2d33-48f6-83fb-29f1244c1289.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.17367151791778357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a5b28328-4dee-43c7-bc6f-b3827c4f3589/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.816, validation r2_score = 0.156, test r2_score = -0.093\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a5b28328-4dee-43c7-bc6f-b3827c4f3589.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.15553468569967954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b98e084d-d294-41c5-8b26-a9a5f446f07f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.809, validation r2_score = 0.161, test r2_score = -0.021\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b98e084d-d294-41c5-8b26-a9a5f446f07f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.16067980209859134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/bd7d6186-2f4b-479d-8d75-dd249a564b02/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.801, validation r2_score = 0.133, test r2_score = -0.056\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_bd7d6186-2f4b-479d-8d75-dd249a564b02.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.13272950187940735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6fe37712-440b-435f-a0bc-0226e159758e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.893, validation r2_score = 0.155, test r2_score = -0.191\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6fe37712-440b-435f-a0bc-0226e159758e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.15453058475938486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cee5f5e7-ed82-48b0-9702-862b7f176c25/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.891, validation r2_score = 0.140, test r2_score = 0.149\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cee5f5e7-ed82-48b0-9702-862b7f176c25.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.13968362222332498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b09bd674-77a6-426b-91e6-10dc021e74f1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.890, validation r2_score = 0.173, test r2_score = -0.517\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b09bd674-77a6-426b-91e6-10dc021e74f1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.1726822069455055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/31f843d6-80ba-4d79-a9d8-273b295ce528/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.892, validation r2_score = 0.166, test r2_score = -0.271\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_31f843d6-80ba-4d79-a9d8-273b295ce528.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.1657141825166757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/fe904ee7-ff92-4f48-b0a5-873da745c29d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.894, validation r2_score = 0.169, test r2_score = 0.044\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_fe904ee7-ff92-4f48-b0a5-873da745c29d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.1688632941439715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/99c022e0-79f1-4d8a-acd0-57ec528e39a1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.899, validation r2_score = 0.132, test r2_score = -0.317\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_99c022e0-79f1-4d8a-acd0-57ec528e39a1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.1317033627697346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cf3cfd95-0d65-4337-b447-061a5601a666/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.901, validation r2_score = 0.146, test r2_score = 0.211\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cf3cfd95-0d65-4337-b447-061a5601a666.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.1463455125346731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e76516ae-220f-44c9-ad21-0b05fa5b43d3/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.177, test r2_score = -0.400\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e76516ae-220f-44c9-ad21-0b05fa5b43d3.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.1766685014874364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4797c46c-2bbb-4444-9fbb-3dc20fde3eda/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.168, test r2_score = -0.220\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4797c46c-2bbb-4444-9fbb-3dc20fde3eda.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.16776716810313663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2feee930-8cc4-4c7c-9bef-ccc738357436/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.903, validation r2_score = 0.149, test r2_score = -0.068\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2feee930-8cc4-4c7c-9bef-ccc738357436.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.14887253258343525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b62f5060-83d9-42ed-b71f-69925b2ff03e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.902, validation r2_score = 0.145, test r2_score = -0.606\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b62f5060-83d9-42ed-b71f-69925b2ff03e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.14479827445670768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/291d4f18-6782-4885-8585-c8a7923c491a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.151, test r2_score = -0.207\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_291d4f18-6782-4885-8585-c8a7923c491a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.15129284762379314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/80c8b568-7f58-41fa-b426-3c1f1563f43a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.899, validation r2_score = 0.152, test r2_score = -0.318\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_80c8b568-7f58-41fa-b426-3c1f1563f43a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.15220961077388395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9d051d18-1880-4c41-9a45-a84e6bcbae58/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.904, validation r2_score = 0.151, test r2_score = -0.121\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9d051d18-1880-4c41-9a45-a84e6bcbae58.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.15103493652058686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/365c3154-69a6-4f36-806b-2242b8b95c40/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.899, validation r2_score = 0.152, test r2_score = 0.037\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_365c3154-69a6-4f36-806b-2242b8b95c40.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.15183631663752817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/db5f0a2f-3a75-45e6-bc78-eff339bd2996/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.148, test r2_score = -0.895\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_db5f0a2f-3a75-45e6-bc78-eff339bd2996.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.14791461339366607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0ce25835-be24-427a-8d1a-6567f01d784c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.903, validation r2_score = 0.157, test r2_score = 0.094\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0ce25835-be24-427a-8d1a-6567f01d784c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.15702960832655644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b8286f0b-764f-4e98-87b3-797a5e244762/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.138, test r2_score = -0.225\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b8286f0b-764f-4e98-87b3-797a5e244762.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.13848460400050933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/774101da-8cca-4476-9363-985dded411bf/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.134, test r2_score = -0.231\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_774101da-8cca-4476-9363-985dded411bf.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.13445770544683244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e1958159-5e65-43bb-b716-a7284bd2cd19/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.138, test r2_score = 0.018\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e1958159-5e65-43bb-b716-a7284bd2cd19.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.13781710265127056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a6d37e08-69de-4f80-a9ea-1533167405b7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.902, validation r2_score = 0.147, test r2_score = -0.349\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a6d37e08-69de-4f80-a9ea-1533167405b7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.1471556010983317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2486e4ec-e0c6-47a1-8d73-f17a8419a0f5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.903, validation r2_score = 0.156, test r2_score = -0.465\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2486e4ec-e0c6-47a1-8d73-f17a8419a0f5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.1556513495429268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3c01f7d5-ab66-4c6f-90d0-7d4082535123/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.899, validation r2_score = 0.139, test r2_score = -0.482\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3c01f7d5-ab66-4c6f-90d0-7d4082535123.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.13869418706617198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6e1f845b-b05b-4421-b01e-74cb04391a5b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.903, validation r2_score = 0.149, test r2_score = 0.120\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6e1f845b-b05b-4421-b01e-74cb04391a5b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.14883210823014537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/70b7c835-6700-48ce-85f6-95366e9b0cfe/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.900, validation r2_score = 0.159, test r2_score = -0.032\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_70b7c835-6700-48ce-85f6-95366e9b0cfe.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.15923430333854438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f9dbd485-63b9-4e13-aa2f-624e4a4f487f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.822, validation r2_score = 0.179, test r2_score = 0.182\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f9dbd485-63b9-4e13-aa2f-624e4a4f487f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.17925714650001934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/68edea65-1705-478d-baa7-163e6eae1871/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.814, validation r2_score = 0.164, test r2_score = -0.327\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_68edea65-1705-478d-baa7-163e6eae1871.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.1641541575298684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ac07cc1f-dbad-40eb-bf8b-6999a35ad7de/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.814, validation r2_score = 0.171, test r2_score = -0.305\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ac07cc1f-dbad-40eb-bf8b-6999a35ad7de.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.1713445232363866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9de9afde-acf3-4ae5-9f6a-7a130326bf74/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.810, validation r2_score = 0.172, test r2_score = 0.054\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9de9afde-acf3-4ae5-9f6a-7a130326bf74.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.17153721757665608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/067d0347-8400-45ff-bf89-60a1a47a19c5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.805, validation r2_score = 0.179, test r2_score = 0.168\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_067d0347-8400-45ff-bf89-60a1a47a19c5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.17920714333396792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8fbcce9f-de7e-4449-911e-a761ac6d91e2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.902, validation r2_score = 0.175, test r2_score = -0.148\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8fbcce9f-de7e-4449-911e-a761ac6d91e2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.17495264398650645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/eb4d4da6-f67c-4d17-a153-6cdb4cf8848a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.899, validation r2_score = 0.168, test r2_score = -0.393\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_eb4d4da6-f67c-4d17-a153-6cdb4cf8848a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.16786274117612987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/45658e71-1276-4e70-a4c9-e62ddd752490/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.901, validation r2_score = 0.172, test r2_score = -0.286\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_45658e71-1276-4e70-a4c9-e62ddd752490.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.17186320474377959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0e25cf93-a231-414d-b83e-6955068a1fd2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.898, validation r2_score = 0.155, test r2_score = -0.002\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0e25cf93-a231-414d-b83e-6955068a1fd2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.1548334347913961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3ffcab0f-71c3-493d-801a-2cd76807f58c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.897, validation r2_score = 0.159, test r2_score = -0.159\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3ffcab0f-71c3-493d-801a-2cd76807f58c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.15858450253545975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1fdee03a-9565-4eb4-bc1c-5659923bbdd5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.906, validation r2_score = 0.174, test r2_score = -0.178\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1fdee03a-9565-4eb4-bc1c-5659923bbdd5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.1737884879265108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/17ea1f02-2966-43eb-a82f-b6a24c35224a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.906, validation r2_score = 0.171, test r2_score = 0.092\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_17ea1f02-2966-43eb-a82f-b6a24c35224a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.17093171347422043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/fb40fc95-7a1d-4a6d-bf91-b157224e1fce/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.193, test r2_score = -0.256\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_fb40fc95-7a1d-4a6d-bf91-b157224e1fce.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.1933757646916069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/c4896644-b99a-4035-b0b2-63e78be9b355/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.198, test r2_score = -0.654\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_c4896644-b99a-4035-b0b2-63e78be9b355.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.19761963029813734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/7e43bdb2-0d2c-4506-bcac-21fac5aaa914/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.171, test r2_score = -0.215\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_7e43bdb2-0d2c-4506-bcac-21fac5aaa914.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.17094996929613204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/adfa1c54-56c9-4e7f-8670-d97fbcc71bbc/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.905, validation r2_score = 0.169, test r2_score = 0.064\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_adfa1c54-56c9-4e7f-8670-d97fbcc71bbc.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.16932001595267876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/c461c0de-5857-4b76-8afa-88646955c384/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.164, test r2_score = -0.003\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_c461c0de-5857-4b76-8afa-88646955c384.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.1639071844203599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/fc77e730-37aa-4630-938b-79143707916f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.190, test r2_score = 0.126\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_fc77e730-37aa-4630-938b-79143707916f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.18984834990169153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/868e381b-f447-4d5f-8d74-b937a712f65e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.170, test r2_score = 0.018\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_868e381b-f447-4d5f-8d74-b937a712f65e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.1699369886980816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/d1daeadf-24ac-47cd-be8d-8522ce79e569/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.909, validation r2_score = 0.168, test r2_score = 0.221\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_d1daeadf-24ac-47cd-be8d-8522ce79e569.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.16764799095530014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/525f0055-902e-4f1d-9f19-8391d79e955e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.173, test r2_score = -0.646\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_525f0055-902e-4f1d-9f19-8391d79e955e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.17271044125618695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/da775ba1-d667-4f42-8840-27cd3be59711/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.180, test r2_score = 0.165\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_da775ba1-d667-4f42-8840-27cd3be59711.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.18022250419400043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/552434c7-a8b5-467a-9564-1d266eab7811/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.167, test r2_score = -0.339\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_552434c7-a8b5-467a-9564-1d266eab7811.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.16699762859146328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/df7ca0ff-d7f7-4605-a594-8a0b23c850c7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.906, validation r2_score = 0.186, test r2_score = -0.485\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_df7ca0ff-d7f7-4605-a594-8a0b23c850c7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.1856677333331238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/908e6f27-358a-496c-891f-5fc625f795c4/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.195, test r2_score = -0.085\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_908e6f27-358a-496c-891f-5fc625f795c4.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.19511592199484462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5dc76e99-2e82-4d52-93a0-c1e6097ad0c8/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.200, test r2_score = -0.375\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5dc76e99-2e82-4d52-93a0-c1e6097ad0c8.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.1999399672596881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/d64b7f46-5985-4515-a582-de4849322e05/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.178, test r2_score = 0.082\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_d64b7f46-5985-4515-a582-de4849322e05.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.17805304620602225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/59aa1af8-de9b-4453-bc21-fca3627653b1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.167, test r2_score = -0.313\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_59aa1af8-de9b-4453-bc21-fca3627653b1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.1669003032532288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/105d31fe-862b-4b58-a364-add1ef009fca/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.908, validation r2_score = 0.170, test r2_score = 0.101\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_105d31fe-862b-4b58-a364-add1ef009fca.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.16986226974686214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e3d72412-148a-4011-9d7a-5cfddb4129c1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.907, validation r2_score = 0.165, test r2_score = -0.078\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e3d72412-148a-4011-9d7a-5cfddb4129c1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.16451846701459394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1f513010-a1c8-4ca7-9418-933b5fffb09a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.825, validation r2_score = 0.167, test r2_score = -0.081\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1f513010-a1c8-4ca7-9418-933b5fffb09a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.16704678810592988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/c710c221-5bbc-4a2f-acf0-6442ea07c864/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.828, validation r2_score = 0.167, test r2_score = 0.112\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_c710c221-5bbc-4a2f-acf0-6442ea07c864.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.16730470727110036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/99d2eff5-3a17-407b-a7b4-2d328786db6a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.833, validation r2_score = 0.168, test r2_score = -0.121\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_99d2eff5-3a17-407b-a7b4-2d328786db6a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.16801032864317733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8d890243-4539-4f29-9f4e-9c9d39ae9dcc/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.822, validation r2_score = 0.177, test r2_score = -0.035\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8d890243-4539-4f29-9f4e-9c9d39ae9dcc.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.17701741762056133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4f9285d5-6261-468d-9006-fc2e164c1fb0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.808, validation r2_score = 0.165, test r2_score = -0.323\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4f9285d5-6261-468d-9006-fc2e164c1fb0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.1649999029613376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4e4aa6fa-d050-45db-8141-9f9714a51c24/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.903, validation r2_score = 0.181, test r2_score = 0.011\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4e4aa6fa-d050-45db-8141-9f9714a51c24.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.18084619684696945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f0d93b77-af12-4725-bb2f-a1ee979ccd19/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.905, validation r2_score = 0.177, test r2_score = -0.100\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f0d93b77-af12-4725-bb2f-a1ee979ccd19.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.17705903750324292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/898e30d4-46f0-422c-bd02-c298b1ae0ba2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.906, validation r2_score = 0.197, test r2_score = -0.136\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_898e30d4-46f0-422c-bd02-c298b1ae0ba2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.19708915520844095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3d292ed0-b60d-4a90-8ca7-aa09420fca27/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.902, validation r2_score = 0.182, test r2_score = -0.646\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3d292ed0-b60d-4a90-8ca7-aa09420fca27.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.18177669681051556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e160ec5b-7792-4c78-b67e-2ac4f44aa8ec/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.898, validation r2_score = 0.161, test r2_score = -0.002\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e160ec5b-7792-4c78-b67e-2ac4f44aa8ec.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.16088767530723114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/35e169e1-cdc1-4795-9b61-b7d1093bbfd7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.187, test r2_score = -0.231\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_35e169e1-cdc1-4795-9b61-b7d1093bbfd7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.1865591399118086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9df69585-9e2f-4a97-8dda-c9c67fbf6439/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.193, test r2_score = -0.559\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9df69585-9e2f-4a97-8dda-c9c67fbf6439.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.1930374388108148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cc7a34a3-2819-4a1b-984e-e4dd86a50c65/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.197, test r2_score = 0.068\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cc7a34a3-2819-4a1b-984e-e4dd86a50c65.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.19712804175743548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/66960052-331c-4b14-9b1b-7c5a64812357/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.183, test r2_score = -0.176\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_66960052-331c-4b14-9b1b-7c5a64812357.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.18332898410435017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2aeb51e6-e706-4971-9652-be4c9fcc47b9/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.169, test r2_score = -0.066\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2aeb51e6-e706-4971-9652-be4c9fcc47b9.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.1694789388008332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/31895b7f-5f92-45ce-89fc-cf8c47ccb98f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.171, test r2_score = -0.012\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_31895b7f-5f92-45ce-89fc-cf8c47ccb98f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.17068146884186308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/605e878d-ace7-4625-b553-fc8e7d2329f1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.183, test r2_score = -0.151\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_605e878d-ace7-4625-b553-fc8e7d2329f1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.18280045943613588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2886f2ac-b610-4322-8b92-96b460cc95c9/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.188, test r2_score = -0.318\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2886f2ac-b610-4322-8b92-96b460cc95c9.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.18812098738699623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/20f7108c-ba62-42a8-9d63-320e17d65a7e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.914, validation r2_score = 0.174, test r2_score = -0.220\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_20f7108c-ba62-42a8-9d63-320e17d65a7e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.1737009371152618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/27634ab7-ee5c-403b-960b-4c844c606a1e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.171, test r2_score = 0.061\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_27634ab7-ee5c-403b-960b-4c844c606a1e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.17144611450942981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/47b4ef63-58c4-4e8c-a0c3-e5827f16ae20/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.185, test r2_score = -0.625\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_47b4ef63-58c4-4e8c-a0c3-e5827f16ae20.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.184567030991294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/91823b86-ce4b-4ca0-b97f-1caebd897779/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.194, test r2_score = -0.335\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_91823b86-ce4b-4ca0-b97f-1caebd897779.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.19385790355493315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/d7725f31-77eb-4d68-984c-d1dc2f08528f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.188, test r2_score = 0.092\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_d7725f31-77eb-4d68-984c-d1dc2f08528f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.18814822334386627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ce2db8ce-e138-4402-96a7-5041f76d2a6f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.211, test r2_score = -0.223\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ce2db8ce-e138-4402-96a7-5041f76d2a6f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.21119173263628532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4cdc9379-8e00-4fb3-b7d1-9adbf34dee87/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.175, test r2_score = -0.334\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4cdc9379-8e00-4fb3-b7d1-9adbf34dee87.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.17472261537188993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a7a43268-25ca-4de5-b3d3-7676deb43587/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.186, test r2_score = -0.442\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a7a43268-25ca-4de5-b3d3-7676deb43587.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.18578993357078077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/bf7c0382-d393-43d2-a218-6c6fcc7de59d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.193, test r2_score = -0.086\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_bf7c0382-d393-43d2-a218-6c6fcc7de59d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.19257497722969108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/62454ccc-5973-4b00-9c0b-241c0beb8664/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.195, test r2_score = -0.063\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_62454ccc-5973-4b00-9c0b-241c0beb8664.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.19542722911748056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3cbdcdc7-cb27-430f-b60e-6958fb9243e9/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.914, validation r2_score = 0.179, test r2_score = -0.190\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3cbdcdc7-cb27-430f-b60e-6958fb9243e9.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.17873646949727529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/547b68a4-47f7-4632-aa16-aa473eaeeea1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.189, test r2_score = -0.164\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_547b68a4-47f7-4632-aa16-aa473eaeeea1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.18868399928866852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8e1ca40a-b501-4733-b918-9c26e422cd14/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.831, validation r2_score = 0.199, test r2_score = -0.054\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8e1ca40a-b501-4733-b918-9c26e422cd14.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.19858281049159965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1fcfc1e9-398b-4094-867a-9bc125a8ed4f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.836, validation r2_score = 0.196, test r2_score = -0.082\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1fcfc1e9-398b-4094-867a-9bc125a8ed4f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.196330433466396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1e7fc36b-e9b7-42ff-a29b-748775bf3e00/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.832, validation r2_score = 0.192, test r2_score = -0.227\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1e7fc36b-e9b7-42ff-a29b-748775bf3e00.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.19235036906523872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a4143791-dfea-4bfc-98cd-7013c0b32f9b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.831, validation r2_score = 0.189, test r2_score = -0.008\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a4143791-dfea-4bfc-98cd-7013c0b32f9b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.18893315636767372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2652a639-ba54-46cf-92e2-4d03d2014465/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.821, validation r2_score = 0.182, test r2_score = -0.010\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2652a639-ba54-46cf-92e2-4d03d2014465.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.18181856506885774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/070b7938-63d2-415f-9b24-755c34a9e10e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.217, test r2_score = -0.232\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_070b7938-63d2-415f-9b24-755c34a9e10e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.21747532002855552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9ee863db-8edd-4bf8-b141-650f64f72ed1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.201, test r2_score = -0.296\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9ee863db-8edd-4bf8-b141-650f64f72ed1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.20118998742317162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/aef848b1-83b7-444f-a937-f61e60b759d2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.219, test r2_score = -0.309\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_aef848b1-83b7-444f-a937-f61e60b759d2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.21882245419825364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1bc97dde-0ed0-4f58-b571-7dd95faa252e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.909, validation r2_score = 0.194, test r2_score = 0.101\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1bc97dde-0ed0-4f58-b571-7dd95faa252e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.1941669278002478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/328c769c-405b-40d2-8586-97d3387d471b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.904, validation r2_score = 0.204, test r2_score = -0.026\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_328c769c-405b-40d2-8586-97d3387d471b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.20354900849578772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/eaaa4be1-cc0d-43cb-a377-1330f842d14e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.199, test r2_score = -0.111\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_eaaa4be1-cc0d-43cb-a377-1330f842d14e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.19929076674639312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/73283829-a3f6-4179-b06d-0d0829453a67/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.916, validation r2_score = 0.200, test r2_score = -0.376\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_73283829-a3f6-4179-b06d-0d0829453a67.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.20018437890870155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/694aec0f-5ec6-4842-8ed3-02a87c9d039c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.198, test r2_score = 0.165\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_694aec0f-5ec6-4842-8ed3-02a87c9d039c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.1984147468336892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/75065768-1900-485b-8011-0ea5847a25c0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.916, validation r2_score = 0.210, test r2_score = -0.142\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_75065768-1900-485b-8011-0ea5847a25c0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.2095422825467106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/25473b9c-391e-4c0d-b72e-b1e87ab8322e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.197, test r2_score = -0.271\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_25473b9c-391e-4c0d-b72e-b1e87ab8322e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.19746365761550633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/19b7de28-adf6-47e2-8c3e-4772a29e7879/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.916, validation r2_score = 0.208, test r2_score = -0.238\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_19b7de28-adf6-47e2-8c3e-4772a29e7879.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.2077894326629881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6be1cdcd-ff65-4902-be48-3451919d62c7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.206, test r2_score = 0.027\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6be1cdcd-ff65-4902-be48-3451919d62c7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.20560228950165116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cfb574dc-1450-493e-ad95-e21e7efb4141/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.202, test r2_score = -0.327\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cfb574dc-1450-493e-ad95-e21e7efb4141.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.20176342294644667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/65e0d454-4b20-4995-bb74-f6c5a6c36b1a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.194, test r2_score = -0.121\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_65e0d454-4b20-4995-bb74-f6c5a6c36b1a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.19368504134433173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/576db375-b537-4e5c-bb03-e9ca69e58ea3/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.192, test r2_score = -0.345\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_576db375-b537-4e5c-bb03-e9ca69e58ea3.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.192491880792534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9636438a-8daf-4c5e-b771-aa3b52b29c36/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.201, test r2_score = 0.024\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9636438a-8daf-4c5e-b771-aa3b52b29c36.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.20116737330845036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6726dc00-124c-4fb5-b309-172384550373/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.197, test r2_score = -0.110\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6726dc00-124c-4fb5-b309-172384550373.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.19740942261186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2b423d01-e2d4-416f-976b-3a446b0cc175/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.199, test r2_score = -0.039\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2b423d01-e2d4-416f-976b-3a446b0cc175.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.19905151840469082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3bfc93cb-bd78-48f3-a3fe-b096abebdf18/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.199, test r2_score = -0.167\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3bfc93cb-bd78-48f3-a3fe-b096abebdf18.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.1990988119903805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6bd490b9-af71-47c4-94d0-41378b331584/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.194, test r2_score = -0.206\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6bd490b9-af71-47c4-94d0-41378b331584.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.1944413766799783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e08feedd-dd30-4961-9db2-f2ab9a7af9ce/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.200, test r2_score = -0.185\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e08feedd-dd30-4961-9db2-f2ab9a7af9ce.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.1997187716347666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/7bbcde3a-d0ba-415b-9ced-a76d25d0776f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.197, test r2_score = 0.043\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_7bbcde3a-d0ba-415b-9ced-a76d25d0776f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.19720714998288147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ef13f1e7-16b1-4870-afea-e58663e8085a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.201, test r2_score = -0.055\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ef13f1e7-16b1-4870-afea-e58663e8085a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.20144937410718644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/376e1f19-5612-4404-9df5-75b920150d0f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.209, test r2_score = -0.084\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_376e1f19-5612-4404-9df5-75b920150d0f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.20934666960362225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/afb8772a-e85e-4634-9773-85f66be81e52/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.917, validation r2_score = 0.180, test r2_score = -0.009\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_afb8772a-e85e-4634-9773-85f66be81e52.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.180378932532129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1fc38a29-0155-4643-bf9d-5b294b27d10f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.833, validation r2_score = 0.197, test r2_score = -0.000\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1fc38a29-0155-4643-bf9d-5b294b27d10f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.19673260599417441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/d362434a-f283-4de7-94ba-ff879161d897/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.831, validation r2_score = 0.198, test r2_score = -0.158\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_d362434a-f283-4de7-94ba-ff879161d897.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.19769223616177256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9a0df294-2332-48e5-9c2d-d2ab617938be/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.837, validation r2_score = 0.202, test r2_score = -0.062\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9a0df294-2332-48e5-9c2d-d2ab617938be.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.20193564804385034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/156a93ed-3e5e-4aeb-a807-04ea6eea500c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.833, validation r2_score = 0.201, test r2_score = -0.047\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_156a93ed-3e5e-4aeb-a807-04ea6eea500c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.20147377042038594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2b6362c3-d4b3-4b2d-be8a-a6e0e4e77708/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.814, validation r2_score = 0.191, test r2_score = 0.102\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2b6362c3-d4b3-4b2d-be8a-a6e0e4e77708.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.19057573438525177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4c6a1cb7-abe4-4db7-8b1b-305ab42f11a5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.216, test r2_score = -0.278\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4c6a1cb7-abe4-4db7-8b1b-305ab42f11a5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.21605429931455045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3b2dddae-4528-4743-b64b-6afa4750e4a5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.218, test r2_score = -0.174\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3b2dddae-4528-4743-b64b-6afa4750e4a5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.21824894952042728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/237f8eed-2c37-4fed-8ca8-4ce70031c941/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.912, validation r2_score = 0.209, test r2_score = -0.115\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_237f8eed-2c37-4fed-8ca8-4ce70031c941.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.20866637545495026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5b9053a0-0d8f-4f1d-822d-63259ad06164/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.203, test r2_score = -0.162\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5b9053a0-0d8f-4f1d-822d-63259ad06164.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.20343724460534207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e170cd82-f289-4c6b-a409-b659ba862090/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.909, validation r2_score = 0.207, test r2_score = 0.008\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e170cd82-f289-4c6b-a409-b659ba862090.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.20726898634320834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a1a24715-47a0-4090-a3e5-63172668be18/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.204, test r2_score = 0.070\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a1a24715-47a0-4090-a3e5-63172668be18.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.2042559915130201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5161b53d-8bf6-4aae-9290-a513cf0af6b0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.209, test r2_score = -0.131\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5161b53d-8bf6-4aae-9290-a513cf0af6b0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.20893597416787413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8f0b37b4-49a6-4b74-9cd3-8ceef2b1fe39/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.208, test r2_score = -0.006\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8f0b37b4-49a6-4b74-9cd3-8ceef2b1fe39.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.2079728457140464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0fceb10e-3707-47a1-8f24-4b41a697974d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.210, test r2_score = -0.300\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0fceb10e-3707-47a1-8f24-4b41a697974d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.21027561199232314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/99e010e1-0e78-4cfb-b570-f68255c84dd4/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.198, test r2_score = 0.054\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_99e010e1-0e78-4cfb-b570-f68255c84dd4.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.19834110980858544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a039376b-e175-412f-a6cd-9d4a1c77ae8d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.918, validation r2_score = 0.209, test r2_score = -0.014\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a039376b-e175-412f-a6cd-9d4a1c77ae8d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.20865456133836913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/dc09d250-7515-46bf-a56e-cba5e55bd047/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.205, test r2_score = -0.211\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_dc09d250-7515-46bf-a56e-cba5e55bd047.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.20456471383421015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2e1d8678-e458-46d9-ab0d-269455791e0c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.202, test r2_score = -0.218\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2e1d8678-e458-46d9-ab0d-269455791e0c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.20155358481440366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/de40018b-f4ec-467a-aa51-399f7e8a7517/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.205, test r2_score = -0.128\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_de40018b-f4ec-467a-aa51-399f7e8a7517.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.20519162670837499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cbcbf61b-0bd3-4bc0-9a3d-c224bba4b6a0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.208, test r2_score = -0.154\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cbcbf61b-0bd3-4bc0-9a3d-c224bba4b6a0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.2082560958576406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/653d0b11-6974-4310-9628-923fa9f1e532/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.208, test r2_score = -0.270\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_653d0b11-6974-4310-9628-923fa9f1e532.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.20755654005860402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/c8fd5b7e-88c6-4726-9d1b-499cf55633db/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.199, test r2_score = -0.188\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_c8fd5b7e-88c6-4726-9d1b-499cf55633db.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.1991743429345073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a23c07e7-bf23-4c19-b5a9-2d2d4e1a2c0c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.209, test r2_score = -0.251\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a23c07e7-bf23-4c19-b5a9-2d2d4e1a2c0c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.2091957112916083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ad4fd2c6-1893-4e05-8dbd-6ca0ed829d64/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.208, test r2_score = -0.161\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ad4fd2c6-1893-4e05-8dbd-6ca0ed829d64.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.20807690281798263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/75df0f6a-c669-43a7-9e38-27651bc5f3fb/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.208, test r2_score = -0.212\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_75df0f6a-c669-43a7-9e38-27651bc5f3fb.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.2078420278863975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/09b6bc3e-2cc8-4ccb-83ed-2d66228eeec3/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.919, validation r2_score = 0.205, test r2_score = -0.105\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_09b6bc3e-2cc8-4ccb-83ed-2d66228eeec3.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.2052849152481233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0301da10-59cf-4b7c-b982-6b4c2bd26840/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.212, test r2_score = -0.065\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0301da10-59cf-4b7c-b982-6b4c2bd26840.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.21150765798341786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/35b9bb83-30e8-4f90-a548-5e55bfc02b68/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.204, test r2_score = -0.346\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_35b9bb83-30e8-4f90-a548-5e55bfc02b68.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.20393495733424793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/33262b80-57a0-4449-997b-3c78ae05570b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.205, test r2_score = -0.135\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_33262b80-57a0-4449-997b-3c78ae05570b.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.2053416184422462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9910fc23-f41a-4fe5-8716-bad20ff7abd6/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.207, test r2_score = 0.067\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9910fc23-f41a-4fe5-8716-bad20ff7abd6.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.20738348202652224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/60567e4c-f492-4eed-a6a1-e94674624e47/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.835, validation r2_score = 0.201, test r2_score = -0.093\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_60567e4c-f492-4eed-a6a1-e94674624e47.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.2012121112903017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/cc33901d-7d0d-420e-b8bc-bddd57febbc1/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.833, validation r2_score = 0.197, test r2_score = -0.047\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_cc33901d-7d0d-420e-b8bc-bddd57febbc1.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.19727895152935804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/61984254-1330-4c44-b3ba-f256e1a74325/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.833, validation r2_score = 0.206, test r2_score = -0.114\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_61984254-1330-4c44-b3ba-f256e1a74325.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.20597402539850163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/3ee862da-0e05-4490-82da-63f0a1cecda2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.834, validation r2_score = 0.200, test r2_score = -0.022\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3ee862da-0e05-4490-82da-63f0a1cecda2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.2001051135973687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8b8de6b0-ccd3-45d7-8eb0-1b810326b74f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.821, validation r2_score = 0.194, test r2_score = 0.079\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8b8de6b0-ccd3-45d7-8eb0-1b810326b74f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.19428865271073248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/c13c07c7-53b5-420e-aa28-98821ec19ddb/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.915, validation r2_score = 0.211, test r2_score = -0.210\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_c13c07c7-53b5-420e-aa28-98821ec19ddb.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.21136371772396711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/d8087eae-041d-43c6-8e29-a936e2ef98ea/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.211, test r2_score = -0.236\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_d8087eae-041d-43c6-8e29-a936e2ef98ea.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.21067914254963405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/53e43a72-9de4-4a1d-9dbb-9b936f86b04b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.214, test r2_score = -0.281\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_53e43a72-9de4-4a1d-9dbb-9b936f86b04b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.21374221743014143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/7bb13046-0207-4a01-8a02-e0fb666fa37b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.208, test r2_score = -0.184\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_7bb13046-0207-4a01-8a02-e0fb666fa37b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.20764558916777942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/faba805b-ad7d-4106-a6a8-2597cab81a17/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.910, validation r2_score = 0.206, test r2_score = -0.013\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_faba805b-ad7d-4106-a6a8-2597cab81a17.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.20602573244500866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e78419b6-483a-4f28-a379-00f3f57fec10/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.211, test r2_score = -0.190\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e78419b6-483a-4f28-a379-00f3f57fec10.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.2112948496552901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0720a581-5519-4c24-8294-edb1c2fb4c58/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.213, test r2_score = -0.037\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0720a581-5519-4c24-8294-edb1c2fb4c58.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.21255622136869645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/55223aa2-b2f4-4c5b-b957-877bbca998b0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.213, test r2_score = -0.091\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_55223aa2-b2f4-4c5b-b957-877bbca998b0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.21293085472342377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f2e2301a-7b85-441c-8e83-9baa776ab9a5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.210, test r2_score = -0.077\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f2e2301a-7b85-441c-8e83-9baa776ab9a5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.2096427104609745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/651777ac-a292-4078-b1d6-6d027ce1e822/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.205, test r2_score = -0.005\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_651777ac-a292-4078-b1d6-6d027ce1e822.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.20530658633380872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0d2627ab-68c4-4d99-8373-c604ab01b08e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.217, test r2_score = -0.145\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0d2627ab-68c4-4d99-8373-c604ab01b08e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.21700078395390243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/09824b20-277f-44a7-bcd3-af3f0026e4b0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.217, test r2_score = -0.138\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_09824b20-277f-44a7-bcd3-af3f0026e4b0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.21657479978861038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/7dc184c7-acd2-4f1f-a8fe-28bcb4063de3/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.214, test r2_score = -0.130\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_7dc184c7-acd2-4f1f-a8fe-28bcb4063de3.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.2137799120181363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2fd4cf1a-2e89-4581-b047-41373a105088/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.215, test r2_score = -0.007\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2fd4cf1a-2e89-4581-b047-41373a105088.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.21460720432388225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/bf53e91e-d387-44ae-9dd7-5574a7f07f05/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.206, test r2_score = 0.035\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_bf53e91e-d387-44ae-9dd7-5574a7f07f05.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.20626851169971983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2440cc6c-e112-4520-995d-04316de108c0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.206, test r2_score = -0.131\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2440cc6c-e112-4520-995d-04316de108c0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.20564782364055223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/2bfcf8fa-0300-4604-9313-23f26cdae2b9/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.219, test r2_score = -0.286\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_2bfcf8fa-0300-4604-9313-23f26cdae2b9.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.21908964798428354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b29d0b15-1054-4ead-91ed-e899d22dd5d4/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.212, test r2_score = -0.096\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b29d0b15-1054-4ead-91ed-e899d22dd5d4.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.21182586882694432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e74af939-6a79-4c45-a6ee-402aa6f8199a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.216, test r2_score = -0.173\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e74af939-6a79-4c45-a6ee-402aa6f8199a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.21645288028606324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8e3d6e81-7806-49db-87e6-63924ecf3dfd/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.208, test r2_score = -0.034\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8e3d6e81-7806-49db-87e6-63924ecf3dfd.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.20805713655323088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/b00e6165-0074-4091-bbce-f092ec062104/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.920, validation r2_score = 0.210, test r2_score = -0.184\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_b00e6165-0074-4091-bbce-f092ec062104.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.20973638519265225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4affa40c-0e47-417a-96bf-9f95fddb69d8/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.217, test r2_score = 0.013\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4affa40c-0e47-417a-96bf-9f95fddb69d8.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.2166140531870565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0769b2a2-1117-40b4-b541-1c4dc9d02d6c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.214, test r2_score = -0.018\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0769b2a2-1117-40b4-b541-1c4dc9d02d6c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.21433723059841248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ff85452a-35cf-4864-91f5-38553c422a1a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.214, test r2_score = -0.054\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ff85452a-35cf-4864-91f5-38553c422a1a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.21378008771643864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/71624326-2c2c-49bd-9163-913e473a7e18/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.212, test r2_score = -0.124\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_71624326-2c2c-49bd-9163-913e473a7e18.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.21164933013281184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/8bdff5b5-b2a9-44ae-8635-96ac74aff97c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.835, validation r2_score = 0.205, test r2_score = -0.063\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8bdff5b5-b2a9-44ae-8635-96ac74aff97c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.2047228100468288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e4c2734c-9ee4-41d6-bddc-56a62e1edb06/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.839, validation r2_score = 0.203, test r2_score = -0.083\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e4c2734c-9ee4-41d6-bddc-56a62e1edb06.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 24, valid_r2: 0.20321597209231046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f8972aa1-d1d1-41ed-a445-040c98d89cee/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.837, validation r2_score = 0.204, test r2_score = 0.003\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f8972aa1-d1d1-41ed-a445-040c98d89cee.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.20351529205018426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a04789b4-b82f-4987-ae88-cf06d24bfb69/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.832, validation r2_score = 0.202, test r2_score = -0.037\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a04789b4-b82f-4987-ae88-cf06d24bfb69.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.20206850220399397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/4c5f8eae-2b61-4f43-bf89-b350e7e906f2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.821, validation r2_score = 0.194, test r2_score = 0.050\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_4c5f8eae-2b61-4f43-bf89-b350e7e906f2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.193509416096038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9b07fc50-29f0-4b9e-9e0e-19e1af41a283/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.915, validation r2_score = 0.214, test r2_score = -0.121\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9b07fc50-29f0-4b9e-9e0e-19e1af41a283.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 16, valid_r2: 0.21393096314989857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/e1a709bf-dfa4-4f2e-8cf5-97162a3f2b71/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.914, validation r2_score = 0.213, test r2_score = -0.179\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_e1a709bf-dfa4-4f2e-8cf5-97162a3f2b71.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 24, valid_r2: 0.21326818727117447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/fc628b9e-f861-4e89-813c-4cc81407c8d4/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.914, validation r2_score = 0.212, test r2_score = -0.043\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_fc628b9e-f861-4e89-813c-4cc81407c8d4.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 32, valid_r2: 0.21219584224084453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/a0277ce0-a214-44fe-9501-1b92ff933504/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.913, validation r2_score = 0.213, test r2_score = -0.100\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_a0277ce0-a214-44fe-9501-1b92ff933504.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 64, valid_r2: 0.21340765408073936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/954d245f-48c6-4df8-9c1a-ac3d741aff25/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.911, validation r2_score = 0.208, test r2_score = -0.043\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_954d245f-48c6-4df8-9c1a-ac3d741aff25.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 128, valid_r2: 0.20844751600659017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/011565be-81a9-4ae1-be0f-109de83bfdb7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.214, test r2_score = -0.097\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_011565be-81a9-4ae1-be0f-109de83bfdb7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.2142707776142624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5f3c0ec9-38c1-4043-9064-32eda41a5fc2/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.213, test r2_score = -0.079\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5f3c0ec9-38c1-4043-9064-32eda41a5fc2.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 24, valid_r2: 0.21332967049741258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5db61182-7f58-4d20-a932-8f40e74e343d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.216, test r2_score = -0.188\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5db61182-7f58-4d20-a932-8f40e74e343d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.21643468304040703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ed9ce2c7-329e-455e-af99-c6ddae4e5d63/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.213, test r2_score = -0.084\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ed9ce2c7-329e-455e-af99-c6ddae4e5d63.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.2134100397185229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/15e9eaa4-269f-40b0-b025-c1f5c38ccd46/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.210, test r2_score = -0.018\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_15e9eaa4-269f-40b0-b025-c1f5c38ccd46.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.20975055099351936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0552a70a-064c-4e95-8ca4-ea709d1e727d/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.210, test r2_score = -0.171\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0552a70a-064c-4e95-8ca4-ea709d1e727d.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.20952228591321753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/0d4d9bc1-4354-4385-bc7d-d1004e3c0a2a/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.213, test r2_score = -0.148\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0d4d9bc1-4354-4385-bc7d-d1004e3c0a2a.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 24, valid_r2: 0.213028425175935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f82de6c6-5130-4062-8ecc-25a5f555d129/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.214, test r2_score = -0.199\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f82de6c6-5130-4062-8ecc-25a5f555d129.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.21358046432020927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/615e2ab5-81d4-438f-bdb5-b27e4339fcdb/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.215, test r2_score = -0.069\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_615e2ab5-81d4-438f-bdb5-b27e4339fcdb.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.21472088639724551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/778a1d16-54a1-44d0-865f-0d1c00adf464/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.212, test r2_score = -0.051\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_778a1d16-54a1-44d0-865f-0d1c00adf464.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.21237599111264538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1b65fe8c-d870-4296-8e06-f59cd059b60f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.215, test r2_score = -0.064\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1b65fe8c-d870-4296-8e06-f59cd059b60f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.21493967039709105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/eed8ffcc-4b9a-47ab-817f-cb97cccce8b0/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.213, test r2_score = -0.055\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_eed8ffcc-4b9a-47ab-817f-cb97cccce8b0.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 24, valid_r2: 0.21258236988811618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/6795109c-548d-4286-8af5-65f38d0d8d73/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.216, test r2_score = -0.144\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_6795109c-548d-4286-8af5-65f38d0d8d73.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.21602417712656752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/daa893ea-366f-4127-95d8-6fe1a237067e/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.215, test r2_score = -0.115\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_daa893ea-366f-4127-95d8-6fe1a237067e.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.21544220692093563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/9ff2f530-3e3c-492d-a5f5-4835dac327c7/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.211, test r2_score = 0.019\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_9ff2f530-3e3c-492d-a5f5-4835dac327c7.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.2111471488427027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/1569dc23-ecc4-48d0-97ae-f267dc03b97c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.215, test r2_score = -0.105\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1569dc23-ecc4-48d0-97ae-f267dc03b97c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 16, valid_r2: 0.21507337375154867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/5f456672-d975-443c-be6f-359342e4c008/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.209, test r2_score = -0.228\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5f456672-d975-443c-be6f-359342e4c008.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 24, valid_r2: 0.20902177578191572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/f3f57bbf-9bcb-46a7-95d2-c9ab6c8d918c/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.921, validation r2_score = 0.214, test r2_score = -0.134\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_f3f57bbf-9bcb-46a7-95d2-c9ab6c8d918c.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 32, valid_r2: 0.21426767640283895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/ded4095e-2e9e-42e4-a6e3-6e68fc33a6f5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.217, test r2_score = -0.145\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_ded4095e-2e9e-42e4-a6e3-6e68fc33a6f5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 64, valid_r2: 0.21678202451589546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Got dataset, attempting to extract data\n",
      "DEBUG:ATOM:Creating deepchem dataset\n",
      "INFO:ATOM:Using prefeaturized data; number of features = 200\n",
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/RF_computed_descriptors_scaffold_regression/583bac7a-b8b4-4450-95df-957374523f7f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/transformations.py:255: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = np.nan_to_num((X - self.X_means) * X_weight / self.X_stds)\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming feature data\n",
      "INFO:ATOM:Fitting random forest model\n",
      "INFO:ATOM:Fold 0: training r2_score = 0.922, validation r2_score = 0.210, test r2_score = -0.087\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_583bac7a-b8b4-4450-95df-957374523f7f.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 128, valid_r2: 0.20972982758172243\n"
     ]
    }
   ],
   "source": [
    "# # 210 models per feature set\n",
    "# estimator_choice = [512]\n",
    "# depth_choice = [128]\n",
    "# features_choice = [64] #16,24,32,64,128, # can only be < total number of features\n",
    "\n",
    "estimator_choice = [16,24,32,64,128,256,512]\n",
    "depth_choice = [16,24,32,64,128,256]\n",
    "features_choice = [16,24,32,64,128] #16,24,32,64,128, # can only be < total number of features\n",
    "\n",
    "for rf_estimator in estimator_choice:\n",
    "  for rf_depth in depth_choice:\n",
    "    for rf_max_feature in features_choice:\n",
    "        params[\"rf_estimators\"] = rf_estimator\n",
    "        params[\"rf_max_depth\"] = rf_depth\n",
    "        params[\"rf_max_features\"] = rf_max_feature\n",
    "        tp = parse.wrapper(params)\n",
    "        pl = mp.ModelPipeline(tp)\n",
    "        pl.train_model()\n",
    "        pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
    "        pred_results = pred_data.get_prediction_results()\n",
    "        print(f\"rf_estimators: {rf_estimator}, rf_max_depth: {rf_depth}, rf_max_features: {rf_max_feature}, valid_r2: {pred_results['r2_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - RF (parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 210 models per feature set\n",
    "estimator_choice = [16,24,32,64,128,256,512]\n",
    "depth_choice = [16,24,32,64,128,256]\n",
    "features_choice = [16,24,32,64,128] #16,24,32,64,128, # can only be < total number of features\n",
    "\n",
    "param_combos = [] # list of params dict: each element is a params dict with specific set of leyrs,dropouts, lr_rate combinations\n",
    "for rf_estimator in estimator_choice:\n",
    "  for rf_depth in depth_choice:\n",
    "    for rf_max_feature in features_choice:\n",
    "        params[\"rf_estimators\"] = rf_estimator\n",
    "        params[\"rf_max_depth\"] = rf_depth\n",
    "        params[\"rf_max_features\"] = rf_max_feature\n",
    "        param_combos.append(params)\n",
    "print(\" total models = \", len(param_combos))\n",
    "\n",
    "def parallelrun(params_):\n",
    "    tp = parse.wrapper(params_)\n",
    "    pl = mp.ModelPipeline(tp)\n",
    "    pl.train_model()\n",
    "start=time.time()\n",
    "cores = 4 #multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=cores, timeout=99999)(delayed(parallelrun)(params_)for params_ in param_combos)\n",
    "print(\" Time taken to create \", len(param_combos), \"RF models(min)= \", np.round((time.time()-start)/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " 'collection_name': 'CYP2D6',\n",
    " 'dataset_key': data_file,\n",
    " 'datastore': 'False',\n",
    " \"featurizer\": \"graphconv\", #\"computed_descriptors\",\n",
    " #\"descriptor_type\": \"rdkit_raw\", #mordred_filtered\",\n",
    " #'hyperparam': 'True',\n",
    " 'id_col': 'compound_id',\n",
    " 'model_type': 'NN',\n",
    " 'prediction_type': 'regression',\n",
    " 'previously_split': 'True',\n",
    " 'split_uuid': split_uuid,\n",
    " 'rerun': 'False',\n",
    " 'response_cols': 'pIC50',\n",
    " 'result_dir': outdir,\n",
    " 'save_results': 'False',\n",
    " 'search_type': 'user_specified',\n",
    " 'smiles_col': 'base_rdkit_smiles',\n",
    " 'split_only': 'False',\n",
    " #'split_test_frac': '0.002',\n",
    " #'split_valid_frac': '0.15',\n",
    " 'splitter': 'scaffold',\n",
    " 'transformers': 'True',\n",
    " 'uncertainty': 'True',\n",
    " #\"dropouts\": \"0.10,0.10,0.10\",\n",
    " #\"layer_sizes\": \"64,64,64\",\n",
    " #\"learning_rate\": \"0.000753\",\n",
    " 'verbose': 'True'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n",
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/8cb766e2-04f6-4d8e-a607-94063802f8ef/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_14:0\", shape=(177,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_13:0\", shape=(177, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_17:0\", shape=(1496,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_16:0\", shape=(1496, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_20:0\", shape=(1221,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_19:0\", shape=(1221, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_23:0\", shape=(72,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_22:0\", shape=(72, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_14:0\", shape=(220,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_13:0\", shape=(220, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_17:0\", shape=(1506,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_16:0\", shape=(1506, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_20:0\", shape=(1326,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_19:0\", shape=(1326, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_23:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_22:0\", shape=(108, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_25:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Reshape_28:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_1/graph_pool_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -2.42\n",
      "INFO:ATOM:Epoch 0: training r2_score = -2.030, validation r2_score = -2.419, test r2_score = -2.090\n",
      "INFO:ATOM:*** Total score for epoch 1 is -0.502, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = -0.378, validation r2_score = -0.502, test r2_score = -0.782\n",
      "INFO:ATOM:*** Total score for epoch 2 is -0.294, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = -0.157, validation r2_score = -0.294, test r2_score = -0.337\n",
      "INFO:ATOM:*** Total score for epoch 3 is -0.0504, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.029, validation r2_score = -0.050, test r2_score = -0.075\n",
      "INFO:ATOM:Epoch 4: training r2_score = -0.013, validation r2_score = -0.118, test r2_score = -0.034\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.026, validation r2_score = -0.070, test r2_score = 0.032\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.034, validation r2_score = -0.053, test r2_score = 0.080\n",
      "INFO:ATOM:*** Total score for epoch 7 is -0.0323, is new maximum\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.055, validation r2_score = -0.032, test r2_score = -0.034\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.020, validation r2_score = -0.070, test r2_score = 0.018\n",
      "INFO:ATOM:Epoch 9: training r2_score = -0.001, validation r2_score = -0.096, test r2_score = -0.016\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.041, validation r2_score = -0.077, test r2_score = -0.010\n",
      "INFO:ATOM:*** Total score for epoch 11 is -0.00355, is new maximum\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.081, validation r2_score = -0.004, test r2_score = -0.021\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.060, validation r2_score = -0.068, test r2_score = 0.025\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.057, validation r2_score = -0.082, test r2_score = 0.082\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.089, validation r2_score = -0.061, test r2_score = 0.188\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.102, validation r2_score = -0.027, test r2_score = 0.287\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.113, validation r2_score = -0.024, test r2_score = 0.187\n",
      "INFO:ATOM:*** Total score for epoch 17 is 0.00574, is new maximum\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.132, validation r2_score = 0.006, test r2_score = 0.195\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.123, validation r2_score = -0.015, test r2_score = 0.134\n",
      "INFO:ATOM:*** Total score for epoch 19 is 0.0248, is new maximum\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.134, validation r2_score = 0.025, test r2_score = 0.253\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.090, validation r2_score = -0.029, test r2_score = 0.207\n",
      "INFO:ATOM:*** Total score for epoch 21 is 0.0335, is new maximum\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.146, validation r2_score = 0.034, test r2_score = 0.256\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.170, validation r2_score = 0.031, test r2_score = 0.237\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.154, validation r2_score = -0.001, test r2_score = 0.212\n",
      "INFO:ATOM:*** Total score for epoch 24 is 0.0452, is new maximum\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.184, validation r2_score = 0.045, test r2_score = 0.210\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.161, validation r2_score = 0.021, test r2_score = 0.169\n",
      "INFO:ATOM:*** Total score for epoch 26 is 0.0726, is new maximum\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.216, validation r2_score = 0.073, test r2_score = 0.282\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.203, validation r2_score = 0.058, test r2_score = 0.331\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.182, validation r2_score = 0.013, test r2_score = 0.253\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.195, validation r2_score = 0.044, test r2_score = 0.225\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/8cb766e2-04f6-4d8e-a607-94063802f8ef/best_model'\n",
      "INFO:ATOM:Best model from epoch 26 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/8cb766e2-04f6-4d8e-a607-94063802f8ef/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_8cb766e2-04f6-4d8e-a607-94063802f8ef.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 128,32, dropouts: 0.5,0.5, learning rate: 0.0007, valid_r2: 0.07260191088157875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/3add0f23-dc2a-40cb-a99f-edbf3c4cd9eb/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_14:0\", shape=(204,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_13:0\", shape=(204, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_17:0\", shape=(1418,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_16:0\", shape=(1418, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_20:0\", shape=(1194,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_19:0\", shape=(1194, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_23:0\", shape=(112,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_22:0\", shape=(112, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_14:0\", shape=(198,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_13:0\", shape=(198, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_17:0\", shape=(1512,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_16:0\", shape=(1512, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_20:0\", shape=(1230,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_19:0\", shape=(1230, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_22:0\", shape=(88, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_13:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_16:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_19:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_22:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_25:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Reshape_28:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_3/graph_pool_3/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6321 calls to <function KerasModel._compute_model at 0x7f360e64c9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6321 calls to <function KerasModel._compute_model at 0x7f360e64c9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:ATOM:Total score for epoch 0 is -0.033\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.021, validation r2_score = -0.033, test r2_score = 0.385\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.0512, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.082, validation r2_score = 0.051, test r2_score = 0.091\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0525, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.069, validation r2_score = 0.052, test r2_score = 0.266\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.070, validation r2_score = -0.004, test r2_score = 0.197\n",
      "INFO:ATOM:*** Total score for epoch 4 is 0.0795, is new maximum\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.144, validation r2_score = 0.079, test r2_score = 0.185\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.115, validation r2_score = 0.044, test r2_score = 0.191\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.048, validation r2_score = 0.002, test r2_score = 0.271\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.108, validation r2_score = 0.045, test r2_score = 0.131\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.135, validation r2_score = 0.059, test r2_score = 0.091\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.115, validation r2_score = 0.006, test r2_score = 0.072\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.088, validation r2_score = 0.022, test r2_score = 0.431\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.145, validation r2_score = 0.073, test r2_score = 0.353\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.143, validation r2_score = 0.058, test r2_score = 0.185\n",
      "INFO:ATOM:*** Total score for epoch 13 is 0.0831, is new maximum\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.174, validation r2_score = 0.083, test r2_score = 0.173\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.170, validation r2_score = 0.079, test r2_score = 0.089\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.170, validation r2_score = 0.070, test r2_score = 0.159\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.174, validation r2_score = 0.071, test r2_score = 0.186\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.146, validation r2_score = 0.053, test r2_score = 0.143\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.107, validation r2_score = -0.021, test r2_score = -0.095\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.178, validation r2_score = 0.064, test r2_score = 0.192\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.209, validation r2_score = 0.074, test r2_score = 0.294\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.149, validation r2_score = -0.014, test r2_score = 0.147\n",
      "INFO:ATOM:*** Total score for epoch 22 is 0.0847, is new maximum\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.204, validation r2_score = 0.085, test r2_score = 0.295\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.166, validation r2_score = 0.008, test r2_score = 0.231\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.187, validation r2_score = 0.084, test r2_score = 0.312\n",
      "INFO:ATOM:*** Total score for epoch 25 is 0.093, is new maximum\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.202, validation r2_score = 0.093, test r2_score = 0.272\n",
      "INFO:ATOM:*** Total score for epoch 26 is 0.0936, is new maximum\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.212, validation r2_score = 0.094, test r2_score = 0.336\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.171, validation r2_score = 0.048, test r2_score = 0.395\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.217, validation r2_score = 0.070, test r2_score = 0.116\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.189, validation r2_score = 0.044, test r2_score = 0.302\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/3add0f23-dc2a-40cb-a99f-edbf3c4cd9eb/best_model'\n",
      "INFO:ATOM:Best model from epoch 26 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/3add0f23-dc2a-40cb-a99f-edbf3c4cd9eb/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_3add0f23-dc2a-40cb-a99f-edbf3c4cd9eb.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 128,32, dropouts: 0.5,0.5, learning rate: 0.005, valid_r2: 0.09363695684746032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/48b30b62-50a1-4fcc-a749-cbd0ee3d15e6/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_14:0\", shape=(187,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_13:0\", shape=(187, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_17:0\", shape=(1480,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_16:0\", shape=(1480, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_20:0\", shape=(1227,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_19:0\", shape=(1227, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_23:0\", shape=(60,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_22:0\", shape=(60, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_14:0\", shape=(214,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_13:0\", shape=(214, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_17:0\", shape=(1408,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_16:0\", shape=(1408, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_20:0\", shape=(1188,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_19:0\", shape=(1188, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_23:0\", shape=(132,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_22:0\", shape=(132, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_5/graph_pool_5/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6321 calls to <function KerasModel._compute_model at 0x7f3663858320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6321 calls to <function KerasModel._compute_model at 0x7f3663858320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:ATOM:Total score for epoch 0 is -0.376\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.358, validation r2_score = -0.376, test r2_score = -0.637\n",
      "INFO:ATOM:*** Total score for epoch 1 is -0.127, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = -0.050, validation r2_score = -0.127, test r2_score = 0.125\n",
      "INFO:ATOM:*** Total score for epoch 2 is -0.0428, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.040, validation r2_score = -0.043, test r2_score = 0.387\n",
      "INFO:ATOM:*** Total score for epoch 3 is 0.0399, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.105, validation r2_score = 0.040, test r2_score = 0.419\n",
      "INFO:ATOM:*** Total score for epoch 4 is 0.0488, is new maximum\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.129, validation r2_score = 0.049, test r2_score = 0.401\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.131, validation r2_score = 0.038, test r2_score = 0.413\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.110, validation r2_score = 0.029, test r2_score = 0.486\n",
      "INFO:ATOM:*** Total score for epoch 7 is 0.063, is new maximum\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.165, validation r2_score = 0.063, test r2_score = 0.375\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.167, validation r2_score = 0.058, test r2_score = 0.351\n",
      "INFO:ATOM:*** Total score for epoch 9 is 0.0697, is new maximum\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.162, validation r2_score = 0.070, test r2_score = 0.424\n",
      "INFO:ATOM:*** Total score for epoch 10 is 0.0753, is new maximum\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.166, validation r2_score = 0.075, test r2_score = 0.473\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.131, validation r2_score = 0.001, test r2_score = 0.349\n",
      "INFO:ATOM:*** Total score for epoch 12 is 0.0818, is new maximum\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.186, validation r2_score = 0.082, test r2_score = 0.275\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.163, validation r2_score = 0.045, test r2_score = 0.228\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.187, validation r2_score = 0.071, test r2_score = 0.318\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.149, validation r2_score = 0.023, test r2_score = 0.285\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.185, validation r2_score = 0.066, test r2_score = 0.250\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.197, validation r2_score = 0.063, test r2_score = 0.227\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.194, validation r2_score = 0.052, test r2_score = 0.332\n",
      "INFO:ATOM:*** Total score for epoch 19 is 0.0864, is new maximum\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.211, validation r2_score = 0.086, test r2_score = 0.392\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.215, validation r2_score = 0.079, test r2_score = 0.242\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.204, validation r2_score = 0.077, test r2_score = 0.171\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.197, validation r2_score = 0.028, test r2_score = 0.164\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.219, validation r2_score = 0.085, test r2_score = 0.383\n",
      "INFO:ATOM:*** Total score for epoch 24 is 0.0889, is new maximum\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.227, validation r2_score = 0.089, test r2_score = 0.371\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.232, validation r2_score = 0.072, test r2_score = 0.280\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.242, validation r2_score = 0.076, test r2_score = 0.369\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.252, validation r2_score = 0.087, test r2_score = 0.299\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.242, validation r2_score = 0.085, test r2_score = 0.380\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.253, validation r2_score = 0.073, test r2_score = 0.362\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/48b30b62-50a1-4fcc-a749-cbd0ee3d15e6/best_model'\n",
      "INFO:ATOM:Best model from epoch 24 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/48b30b62-50a1-4fcc-a749-cbd0ee3d15e6/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_48b30b62-50a1-4fcc-a749-cbd0ee3d15e6.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 256,64, dropouts: 0.5,0.5, learning rate: 0.0007, valid_r2: 0.0888652658995932\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/09b75184-8b59-48f9-8650-eb377e603bbf/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_14:0\", shape=(207,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_13:0\", shape=(207, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_17:0\", shape=(1442,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_16:0\", shape=(1442, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_20:0\", shape=(1227,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_19:0\", shape=(1227, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_23:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_22:0\", shape=(100, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_14:0\", shape=(204,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_13:0\", shape=(204, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_17:0\", shape=(1512,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_16:0\", shape=(1512, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_20:0\", shape=(1260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_19:0\", shape=(1260, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_22:0\", shape=(88, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_7/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.0279\n",
      "INFO:ATOM:Epoch 0: training r2_score = 0.016, validation r2_score = -0.028, test r2_score = 0.266\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.00453, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.033, validation r2_score = 0.005, test r2_score = 0.224\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0217, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.092, validation r2_score = 0.022, test r2_score = -0.208\n",
      "INFO:ATOM:*** Total score for epoch 3 is 0.0802, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.140, validation r2_score = 0.080, test r2_score = 0.212\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.149, validation r2_score = 0.077, test r2_score = 0.122\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.160, validation r2_score = 0.064, test r2_score = 0.230\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.156, validation r2_score = 0.080, test r2_score = 0.094\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.164, validation r2_score = 0.061, test r2_score = 0.113\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.184, validation r2_score = 0.071, test r2_score = 0.391\n",
      "INFO:ATOM:*** Total score for epoch 9 is 0.0837, is new maximum\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.166, validation r2_score = 0.084, test r2_score = 0.174\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.135, validation r2_score = 0.032, test r2_score = 0.155\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.115, validation r2_score = -0.019, test r2_score = -0.002\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.146, validation r2_score = 0.035, test r2_score = 0.139\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.179, validation r2_score = 0.038, test r2_score = 0.178\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.125, validation r2_score = -0.012, test r2_score = -0.061\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.196, validation r2_score = 0.076, test r2_score = 0.283\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.160, validation r2_score = 0.073, test r2_score = 0.178\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.153, validation r2_score = 0.069, test r2_score = 0.335\n",
      "INFO:ATOM:*** Total score for epoch 18 is 0.111, is new maximum\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.194, validation r2_score = 0.111, test r2_score = 0.387\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.169, validation r2_score = 0.024, test r2_score = 0.165\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.232, validation r2_score = 0.088, test r2_score = 0.227\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.170, validation r2_score = 0.034, test r2_score = 0.098\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.232, validation r2_score = 0.086, test r2_score = 0.253\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.194, validation r2_score = 0.063, test r2_score = 0.264\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.228, validation r2_score = 0.093, test r2_score = 0.298\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.204, validation r2_score = 0.060, test r2_score = 0.184\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.202, validation r2_score = 0.050, test r2_score = 0.306\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.194, validation r2_score = 0.046, test r2_score = 0.199\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.234, validation r2_score = 0.104, test r2_score = 0.307\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.191, validation r2_score = 0.058, test r2_score = 0.192\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/09b75184-8b59-48f9-8650-eb377e603bbf/best_model'\n",
      "INFO:ATOM:Best model from epoch 18 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/09b75184-8b59-48f9-8650-eb377e603bbf/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_09b75184-8b59-48f9-8650-eb377e603bbf.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 256,64, dropouts: 0.5,0.5, learning rate: 0.005, valid_r2: 0.11124856627274715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/52979a41-f2a1-41ca-976e-0ad4093a5297/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_14:0\", shape=(231,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_13:0\", shape=(231, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_17:0\", shape=(1344,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_16:0\", shape=(1344, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_20:0\", shape=(1221,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_19:0\", shape=(1221, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_22:0\", shape=(136, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_14:0\", shape=(203,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_13:0\", shape=(203, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_17:0\", shape=(1464,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_16:0\", shape=(1464, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_20:0\", shape=(1293,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_19:0\", shape=(1293, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_22:0\", shape=(88, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_9/graph_pool_9/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.718\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.651, validation r2_score = -0.718, test r2_score = -0.050\n",
      "INFO:ATOM:*** Total score for epoch 1 is -0.284, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = -0.222, validation r2_score = -0.284, test r2_score = 0.297\n",
      "INFO:ATOM:*** Total score for epoch 2 is -0.0158, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.035, validation r2_score = -0.016, test r2_score = 0.284\n",
      "INFO:ATOM:*** Total score for epoch 3 is 0.0529, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.149, validation r2_score = 0.053, test r2_score = 0.278\n",
      "INFO:ATOM:*** Total score for epoch 4 is 0.0797, is new maximum\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.152, validation r2_score = 0.080, test r2_score = 0.292\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.154, validation r2_score = 0.058, test r2_score = 0.309\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.161, validation r2_score = 0.068, test r2_score = 0.375\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.167, validation r2_score = 0.054, test r2_score = -0.005\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.167, validation r2_score = 0.049, test r2_score = 0.164\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.171, validation r2_score = 0.032, test r2_score = 0.111\n",
      "INFO:ATOM:*** Total score for epoch 10 is 0.0924, is new maximum\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.208, validation r2_score = 0.092, test r2_score = 0.315\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.205, validation r2_score = 0.046, test r2_score = 0.209\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.169, validation r2_score = 0.031, test r2_score = 0.230\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.203, validation r2_score = 0.081, test r2_score = 0.277\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.183, validation r2_score = 0.017, test r2_score = 0.204\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.203, validation r2_score = 0.054, test r2_score = 0.103\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.208, validation r2_score = 0.031, test r2_score = 0.179\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.221, validation r2_score = 0.067, test r2_score = 0.224\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.183, validation r2_score = 0.018, test r2_score = 0.153\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.241, validation r2_score = 0.059, test r2_score = 0.033\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.265, validation r2_score = 0.083, test r2_score = 0.285\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.246, validation r2_score = 0.087, test r2_score = 0.072\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.243, validation r2_score = 0.088, test r2_score = 0.064\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.251, validation r2_score = 0.075, test r2_score = -0.010\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.266, validation r2_score = 0.075, test r2_score = 0.186\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.269, validation r2_score = 0.059, test r2_score = 0.164\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.265, validation r2_score = 0.063, test r2_score = 0.008\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.264, validation r2_score = 0.081, test r2_score = 0.071\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.288, validation r2_score = 0.077, test r2_score = 0.020\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.272, validation r2_score = 0.050, test r2_score = 0.120\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/52979a41-f2a1-41ca-976e-0ad4093a5297/best_model'\n",
      "INFO:ATOM:Best model from epoch 10 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/52979a41-f2a1-41ca-976e-0ad4093a5297/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_52979a41-f2a1-41ca-976e-0ad4093a5297.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 512,128, dropouts: 0.5,0.5, learning rate: 0.0007, valid_r2: 0.09240770909953455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/84c2e17d-d785-4a9d-b1cf-53601ab98200/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_14:0\", shape=(247,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_13:0\", shape=(247, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_17:0\", shape=(1472,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_16:0\", shape=(1472, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_20:0\", shape=(1317,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_19:0\", shape=(1317, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_23:0\", shape=(132,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_22:0\", shape=(132, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_14:0\", shape=(187,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_13:0\", shape=(187, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_17:0\", shape=(1458,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_16:0\", shape=(1458, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_20:0\", shape=(1227,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_19:0\", shape=(1227, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_22:0\", shape=(88, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_11/graph_pool_11/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.00955\n",
      "INFO:ATOM:Epoch 0: training r2_score = 0.032, validation r2_score = -0.010, test r2_score = 0.166\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.0107, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.072, validation r2_score = 0.011, test r2_score = -0.128\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0454, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.112, validation r2_score = 0.045, test r2_score = 0.168\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.090, validation r2_score = 0.019, test r2_score = 0.346\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.118, validation r2_score = 0.034, test r2_score = 0.176\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.105, validation r2_score = 0.008, test r2_score = 0.357\n",
      "INFO:ATOM:*** Total score for epoch 6 is 0.0631, is new maximum\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.143, validation r2_score = 0.063, test r2_score = 0.407\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.015, validation r2_score = -0.074, test r2_score = 0.275\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.063, validation r2_score = -0.014, test r2_score = 0.262\n",
      "INFO:ATOM:*** Total score for epoch 9 is 0.0645, is new maximum\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.176, validation r2_score = 0.064, test r2_score = 0.043\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.135, validation r2_score = 0.047, test r2_score = 0.037\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.017, validation r2_score = -0.115, test r2_score = 0.459\n",
      "INFO:ATOM:*** Total score for epoch 12 is 0.0976, is new maximum\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.198, validation r2_score = 0.098, test r2_score = 0.249\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.188, validation r2_score = 0.095, test r2_score = 0.322\n",
      "INFO:ATOM:Epoch 14: training r2_score = -0.016, validation r2_score = -0.135, test r2_score = 0.226\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.048, validation r2_score = -0.068, test r2_score = 0.494\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.121, validation r2_score = -0.015, test r2_score = 0.446\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.205, validation r2_score = 0.060, test r2_score = 0.399\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.071, validation r2_score = -0.097, test r2_score = 0.517\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.188, validation r2_score = 0.072, test r2_score = 0.452\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.131, validation r2_score = -0.003, test r2_score = 0.426\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.176, validation r2_score = 0.023, test r2_score = 0.207\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.199, validation r2_score = 0.036, test r2_score = 0.122\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.197, validation r2_score = 0.061, test r2_score = 0.233\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.174, validation r2_score = 0.018, test r2_score = 0.255\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.233, validation r2_score = 0.075, test r2_score = 0.328\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.038, validation r2_score = -0.121, test r2_score = 0.155\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.136, validation r2_score = -0.035, test r2_score = 0.322\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.187, validation r2_score = 0.000, test r2_score = 0.381\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.259, validation r2_score = 0.070, test r2_score = 0.235\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/84c2e17d-d785-4a9d-b1cf-53601ab98200/best_model'\n",
      "INFO:ATOM:Best model from epoch 12 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/84c2e17d-d785-4a9d-b1cf-53601ab98200/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_84c2e17d-d785-4a9d-b1cf-53601ab98200.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 512,128, dropouts: 0.5,0.5, learning rate: 0.005, valid_r2: 0.09762333939493573\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/0b2d0f60-2172-4c1f-8289-d8b8769682d4/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_14:0\", shape=(202,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_13:0\", shape=(202, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_17:0\", shape=(1496,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_16:0\", shape=(1496, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_20:0\", shape=(1260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_19:0\", shape=(1260, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_23:0\", shape=(112,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_22:0\", shape=(112, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_11:0\", shape=(202,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_10:0\", shape=(202, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_13:0\", shape=(1496,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_12:0\", shape=(1496, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_15:0\", shape=(1260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_14:0\", shape=(1260, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_17:0\", shape=(112,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_16:0\", shape=(112, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_14:0\", shape=(202,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_13:0\", shape=(202, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_17:0\", shape=(1496,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_16:0\", shape=(1496, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_20:0\", shape=(1260,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_19:0\", shape=(1260, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_23:0\", shape=(112,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_22:0\", shape=(112, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_14:0\", shape=(206,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_13:0\", shape=(206, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_17:0\", shape=(1486,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_16:0\", shape=(1486, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_20:0\", shape=(1314,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_19:0\", shape=(1314, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_23:0\", shape=(64,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_22:0\", shape=(64, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_11:0\", shape=(206,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_10:0\", shape=(206, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_13:0\", shape=(1486,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_12:0\", shape=(1486, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_15:0\", shape=(1314,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_14:0\", shape=(1314, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_17:0\", shape=(64,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_16:0\", shape=(64, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_14:0\", shape=(206,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_13:0\", shape=(206, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_17:0\", shape=(1486,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_16:0\", shape=(1486, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_20:0\", shape=(1314,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_19:0\", shape=(1314, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_23:0\", shape=(64,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_22:0\", shape=(64, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_25:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Reshape_28:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_15/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Reshape_20:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_conv_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_13/graph_pool_14/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.202\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.240, validation r2_score = -0.202, test r2_score = -0.081\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.00943, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.024, validation r2_score = 0.009, test r2_score = 0.069\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0306, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.041, validation r2_score = 0.031, test r2_score = 0.184\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.045, validation r2_score = 0.011, test r2_score = 0.149\n",
      "INFO:ATOM:*** Total score for epoch 4 is 0.0368, is new maximum\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.069, validation r2_score = 0.037, test r2_score = 0.165\n",
      "INFO:ATOM:*** Total score for epoch 5 is 0.0523, is new maximum\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.095, validation r2_score = 0.052, test r2_score = 0.206\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.067, validation r2_score = 0.011, test r2_score = 0.140\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.097, validation r2_score = 0.035, test r2_score = 0.135\n",
      "INFO:ATOM:*** Total score for epoch 8 is 0.0615, is new maximum\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.101, validation r2_score = 0.061, test r2_score = 0.095\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.106, validation r2_score = 0.042, test r2_score = 0.163\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.129, validation r2_score = 0.056, test r2_score = 0.220\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.118, validation r2_score = 0.036, test r2_score = 0.209\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.112, validation r2_score = 0.017, test r2_score = 0.003\n",
      "INFO:ATOM:*** Total score for epoch 13 is 0.0658, is new maximum\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.131, validation r2_score = 0.066, test r2_score = 0.146\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.143, validation r2_score = 0.063, test r2_score = 0.201\n",
      "INFO:ATOM:*** Total score for epoch 15 is 0.067, is new maximum\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.148, validation r2_score = 0.067, test r2_score = 0.234\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.124, validation r2_score = 0.045, test r2_score = 0.109\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.140, validation r2_score = 0.049, test r2_score = 0.085\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.137, validation r2_score = 0.019, test r2_score = 0.026\n",
      "INFO:ATOM:*** Total score for epoch 19 is 0.0702, is new maximum\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.178, validation r2_score = 0.070, test r2_score = 0.086\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.152, validation r2_score = 0.041, test r2_score = 0.021\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.091, validation r2_score = -0.040, test r2_score = -0.084\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.188, validation r2_score = 0.061, test r2_score = 0.032\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.180, validation r2_score = 0.067, test r2_score = 0.061\n",
      "INFO:ATOM:*** Total score for epoch 24 is 0.0833, is new maximum\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.192, validation r2_score = 0.083, test r2_score = 0.004\n",
      "INFO:ATOM:*** Total score for epoch 25 is 0.0877, is new maximum\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.197, validation r2_score = 0.088, test r2_score = 0.109\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.168, validation r2_score = 0.071, test r2_score = 0.084\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.178, validation r2_score = 0.073, test r2_score = 0.170\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.201, validation r2_score = 0.085, test r2_score = 0.193\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.205, validation r2_score = 0.068, test r2_score = 0.116\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/0b2d0f60-2172-4c1f-8289-d8b8769682d4/best_model'\n",
      "INFO:ATOM:Best model from epoch 25 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/0b2d0f60-2172-4c1f-8289-d8b8769682d4/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_0b2d0f60-2172-4c1f-8289-d8b8769682d4.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 256,64,16, dropouts: 0.5,0.5,0.5, learning rate: 0.0007, valid_r2: 0.08769820700698239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/5a9816e9-6152-480d-b7d6-880609e72d6b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_14:0\", shape=(207,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_13:0\", shape=(207, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_17:0\", shape=(1420,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_16:0\", shape=(1420, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_20:0\", shape=(1215,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_19:0\", shape=(1215, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_23:0\", shape=(96,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_22:0\", shape=(96, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_11:0\", shape=(207,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_10:0\", shape=(207, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_13:0\", shape=(1420,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_12:0\", shape=(1420, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_15:0\", shape=(1215,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_14:0\", shape=(1215, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_17:0\", shape=(96,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_16:0\", shape=(96, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_18:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_20:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_22:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_24:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_26:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_28:0\", shape=(0, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_14:0\", shape=(207,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_13:0\", shape=(207, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_17:0\", shape=(1420,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_16:0\", shape=(1420, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_20:0\", shape=(1215,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_19:0\", shape=(1215, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_23:0\", shape=(96,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_22:0\", shape=(96, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_14:0\", shape=(213,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_13:0\", shape=(213, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_17:0\", shape=(1460,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_16:0\", shape=(1460, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_20:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_19:0\", shape=(1239, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_22:0\", shape=(88, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_11:0\", shape=(213,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_10:0\", shape=(213, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_13:0\", shape=(1460,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_12:0\", shape=(1460, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_15:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_14:0\", shape=(1239, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_17:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_16:0\", shape=(88, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_14:0\", shape=(213,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_13:0\", shape=(213, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_17:0\", shape=(1460,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_16:0\", shape=(1460, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_20:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_19:0\", shape=(1239, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_22:0\", shape=(88, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_10:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_12:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_14:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_25:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Reshape_28:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_19/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Reshape_20:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_conv_19/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_15/graph_pool_18/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.00337\n",
      "INFO:ATOM:Epoch 0: training r2_score = 0.013, validation r2_score = -0.003, test r2_score = 0.204\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.0134, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.031, validation r2_score = 0.013, test r2_score = 0.014\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0278, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.050, validation r2_score = 0.028, test r2_score = -0.152\n",
      "INFO:ATOM:*** Total score for epoch 3 is 0.0441, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.041, validation r2_score = 0.044, test r2_score = 0.030\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.063, validation r2_score = 0.023, test r2_score = -0.099\n",
      "INFO:ATOM:Epoch 5: training r2_score = -0.010, validation r2_score = -0.075, test r2_score = -0.185\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.082, validation r2_score = 0.034, test r2_score = -0.013\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.102, validation r2_score = 0.025, test r2_score = 0.114\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.096, validation r2_score = 0.037, test r2_score = 0.117\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.093, validation r2_score = 0.035, test r2_score = -0.164\n",
      "INFO:ATOM:*** Total score for epoch 10 is 0.05, is new maximum\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.111, validation r2_score = 0.050, test r2_score = 0.176\n",
      "INFO:ATOM:*** Total score for epoch 11 is 0.0717, is new maximum\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.134, validation r2_score = 0.072, test r2_score = 0.192\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.137, validation r2_score = 0.068, test r2_score = 0.146\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.115, validation r2_score = 0.056, test r2_score = 0.169\n",
      "INFO:ATOM:*** Total score for epoch 14 is 0.0848, is new maximum\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.149, validation r2_score = 0.085, test r2_score = 0.195\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.150, validation r2_score = 0.055, test r2_score = -0.027\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.126, validation r2_score = 0.000, test r2_score = -0.144\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.171, validation r2_score = 0.069, test r2_score = 0.029\n",
      "INFO:ATOM:*** Total score for epoch 18 is 0.0866, is new maximum\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.159, validation r2_score = 0.087, test r2_score = 0.188\n",
      "INFO:ATOM:*** Total score for epoch 19 is 0.0941, is new maximum\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.170, validation r2_score = 0.094, test r2_score = 0.107\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.160, validation r2_score = 0.078, test r2_score = 0.050\n",
      "INFO:ATOM:*** Total score for epoch 21 is 0.108, is new maximum\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.176, validation r2_score = 0.108, test r2_score = -0.066\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.080, validation r2_score = -0.002, test r2_score = 0.178\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.180, validation r2_score = 0.084, test r2_score = 0.039\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.191, validation r2_score = 0.093, test r2_score = 0.070\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.183, validation r2_score = 0.082, test r2_score = 0.187\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.156, validation r2_score = 0.037, test r2_score = -0.023\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.190, validation r2_score = 0.059, test r2_score = 0.093\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.228, validation r2_score = 0.102, test r2_score = 0.040\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.205, validation r2_score = 0.091, test r2_score = 0.083\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/5a9816e9-6152-480d-b7d6-880609e72d6b/best_model'\n",
      "INFO:ATOM:Best model from epoch 21 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/5a9816e9-6152-480d-b7d6-880609e72d6b/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_5a9816e9-6152-480d-b7d6-880609e72d6b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 256,64,16, dropouts: 0.5,0.5,0.5, learning rate: 0.005, valid_r2: 0.10838180713959622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/61c05b55-b57f-4ee6-8f22-d2b81db6fb4f/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_14:0\", shape=(236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_13:0\", shape=(236, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_17:0\", shape=(1520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_16:0\", shape=(1520, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_20:0\", shape=(1302,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_19:0\", shape=(1302, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_22:0\", shape=(116, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_11:0\", shape=(236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_10:0\", shape=(236, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_13:0\", shape=(1520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_12:0\", shape=(1520, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_15:0\", shape=(1302,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_14:0\", shape=(1302, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_17:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_16:0\", shape=(116, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_14:0\", shape=(236,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_13:0\", shape=(236, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_17:0\", shape=(1520,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_16:0\", shape=(1520, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_20:0\", shape=(1302,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_19:0\", shape=(1302, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_22:0\", shape=(116, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_14:0\", shape=(230,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_13:0\", shape=(230, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_17:0\", shape=(1494,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_16:0\", shape=(1494, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_20:0\", shape=(1362,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_19:0\", shape=(1362, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_23:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_22:0\", shape=(100, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_11:0\", shape=(230,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_10:0\", shape=(230, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_13:0\", shape=(1494,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_12:0\", shape=(1494, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_15:0\", shape=(1362,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_14:0\", shape=(1362, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_17:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_16:0\", shape=(100, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_14:0\", shape=(230,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_13:0\", shape=(230, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_17:0\", shape=(1494,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_16:0\", shape=(1494, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_20:0\", shape=(1362,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_19:0\", shape=(1362, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_23:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_22:0\", shape=(100, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_23/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Reshape_20:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_conv_23/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_17/graph_pool_22/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5258 calls to <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x7f360e011680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5258 calls to <function KerasModel._create_gradient_fn.<locals>.apply_gradient_for_batch at 0x7f360e011680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:ATOM:Total score for epoch 0 is -0.122\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.085, validation r2_score = -0.122, test r2_score = -0.463\n",
      "INFO:ATOM:Epoch 1: training r2_score = -0.111, validation r2_score = -0.187, test r2_score = -0.389\n",
      "INFO:ATOM:*** Total score for epoch 2 is -0.0731, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.024, validation r2_score = -0.073, test r2_score = -0.061\n",
      "INFO:ATOM:*** Total score for epoch 3 is -0.0242, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.042, validation r2_score = -0.024, test r2_score = -0.244\n",
      "INFO:ATOM:Epoch 4: training r2_score = -0.006, validation r2_score = -0.128, test r2_score = -0.384\n",
      "INFO:ATOM:*** Total score for epoch 5 is 0.00322, is new maximum\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.118, validation r2_score = 0.003, test r2_score = 0.164\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.098, validation r2_score = -0.007, test r2_score = 0.149\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.030, validation r2_score = -0.093, test r2_score = 0.051\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.069, validation r2_score = -0.049, test r2_score = 0.080\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.087, validation r2_score = -0.037, test r2_score = -0.028\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.042, validation r2_score = -0.079, test r2_score = 0.016\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.073, validation r2_score = -0.058, test r2_score = 0.104\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.026, validation r2_score = -0.113, test r2_score = -0.034\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.052, validation r2_score = -0.072, test r2_score = 0.159\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.036, validation r2_score = -0.102, test r2_score = -0.090\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.098, validation r2_score = -0.027, test r2_score = 0.135\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.070, validation r2_score = -0.086, test r2_score = 0.029\n",
      "INFO:ATOM:*** Total score for epoch 17 is 0.0492, is new maximum\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.163, validation r2_score = 0.049, test r2_score = 0.286\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.080, validation r2_score = -0.078, test r2_score = 0.127\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.126, validation r2_score = -0.011, test r2_score = 0.175\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.107, validation r2_score = -0.033, test r2_score = 0.079\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.147, validation r2_score = 0.015, test r2_score = 0.119\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.141, validation r2_score = -0.001, test r2_score = 0.103\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.163, validation r2_score = 0.019, test r2_score = 0.100\n",
      "INFO:ATOM:*** Total score for epoch 24 is 0.0554, is new maximum\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.195, validation r2_score = 0.055, test r2_score = 0.309\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.129, validation r2_score = 0.004, test r2_score = 0.188\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.190, validation r2_score = 0.044, test r2_score = 0.375\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.184, validation r2_score = 0.028, test r2_score = 0.224\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.166, validation r2_score = 0.013, test r2_score = 0.299\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.208, validation r2_score = 0.054, test r2_score = 0.351\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/61c05b55-b57f-4ee6-8f22-d2b81db6fb4f/best_model'\n",
      "INFO:ATOM:Best model from epoch 24 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/61c05b55-b57f-4ee6-8f22-d2b81db6fb4f/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_61c05b55-b57f-4ee6-8f22-d2b81db6fb4f.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 512,256,32, dropouts: 0.5,0.5,0.5, learning rate: 0.0007, valid_r2: 0.05544227117330003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1993b8a0-53c1-4669-a206-35b7b777f7f5/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_14:0\", shape=(225,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_13:0\", shape=(225, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_17:0\", shape=(1438,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_16:0\", shape=(1438, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_20:0\", shape=(1299,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_19:0\", shape=(1299, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_23:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_22:0\", shape=(144, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_11:0\", shape=(225,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_10:0\", shape=(225, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_13:0\", shape=(1438,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_12:0\", shape=(1438, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_15:0\", shape=(1299,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_14:0\", shape=(1299, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_17:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_16:0\", shape=(144, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_14:0\", shape=(225,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_13:0\", shape=(225, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_17:0\", shape=(1438,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_16:0\", shape=(1438, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_20:0\", shape=(1299,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_19:0\", shape=(1299, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_23:0\", shape=(144,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_22:0\", shape=(144, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_14:0\", shape=(183,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_13:0\", shape=(183, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_20:0\", shape=(1125,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_19:0\", shape=(1125, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_23:0\", shape=(104,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_22:0\", shape=(104, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_11:0\", shape=(183,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_10:0\", shape=(183, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_15:0\", shape=(1125,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_14:0\", shape=(1125, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_17:0\", shape=(104,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_16:0\", shape=(104, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_14:0\", shape=(183,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_13:0\", shape=(183, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_20:0\", shape=(1125,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_19:0\", shape=(1125, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_23:0\", shape=(104,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_22:0\", shape=(104, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_27/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Reshape_20:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_conv_27/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_19/graph_pool_26/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ATOM:Total score for epoch 0 is -0.00764\n",
      "INFO:ATOM:Epoch 0: training r2_score = 0.016, validation r2_score = -0.008, test r2_score = -0.006\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.00181, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.021, validation r2_score = 0.002, test r2_score = -0.054\n",
      "INFO:ATOM:*** Total score for epoch 2 is 0.0412, is new maximum\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.095, validation r2_score = 0.041, test r2_score = -0.090\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.102, validation r2_score = 0.037, test r2_score = 0.114\n",
      "INFO:ATOM:Epoch 4: training r2_score = -0.150, validation r2_score = -0.265, test r2_score = -0.258\n",
      "INFO:ATOM:*** Total score for epoch 5 is 0.0751, is new maximum\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.121, validation r2_score = 0.075, test r2_score = -0.045\n",
      "INFO:ATOM:*** Total score for epoch 6 is 0.0866, is new maximum\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.142, validation r2_score = 0.087, test r2_score = 0.075\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.142, validation r2_score = 0.058, test r2_score = 0.036\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.107, validation r2_score = 0.055, test r2_score = -0.027\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.102, validation r2_score = 0.009, test r2_score = -0.143\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.126, validation r2_score = 0.064, test r2_score = 0.046\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.154, validation r2_score = 0.071, test r2_score = -0.094\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.060, validation r2_score = -0.052, test r2_score = -0.312\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.154, validation r2_score = 0.061, test r2_score = 0.114\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.078, validation r2_score = -0.018, test r2_score = -0.036\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.150, validation r2_score = 0.058, test r2_score = 0.075\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.143, validation r2_score = 0.071, test r2_score = -0.053\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.160, validation r2_score = 0.054, test r2_score = 0.203\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.193, validation r2_score = 0.055, test r2_score = -0.087\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.102, validation r2_score = -0.011, test r2_score = -0.267\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.187, validation r2_score = 0.049, test r2_score = -0.056\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.150, validation r2_score = 0.055, test r2_score = -0.008\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.166, validation r2_score = 0.054, test r2_score = 0.146\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.147, validation r2_score = 0.045, test r2_score = 0.218\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.164, validation r2_score = 0.053, test r2_score = 0.066\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.218, validation r2_score = 0.069, test r2_score = -0.063\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.204, validation r2_score = 0.078, test r2_score = 0.161\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.214, validation r2_score = 0.076, test r2_score = 0.004\n",
      "INFO:ATOM:*** Total score for epoch 28 is 0.107, is new maximum\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.272, validation r2_score = 0.107, test r2_score = 0.243\n",
      "INFO:ATOM:*** Total score for epoch 29 is 0.114, is new maximum\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.270, validation r2_score = 0.114, test r2_score = 0.198\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1993b8a0-53c1-4669-a206-35b7b777f7f5/best_model'\n",
      "INFO:ATOM:Best model from epoch 29 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1993b8a0-53c1-4669-a206-35b7b777f7f5/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1993b8a0-53c1-4669-a206-35b7b777f7f5.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 512,256,32, dropouts: 0.5,0.5,0.5, learning rate: 0.005, valid_r2: 0.11389018992719846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1a316aff-6a7d-49ed-ad70-98d5285bf32b/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_14:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_13:0\", shape=(196, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_17:0\", shape=(1400,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_16:0\", shape=(1400, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_20:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_19:0\", shape=(1134, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_23:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_22:0\", shape=(100, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_11:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_10:0\", shape=(196, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_13:0\", shape=(1400,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_12:0\", shape=(1400, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_15:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_14:0\", shape=(1134, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_17:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_16:0\", shape=(100, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_14:0\", shape=(196,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_13:0\", shape=(196, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_17:0\", shape=(1400,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_16:0\", shape=(1400, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_20:0\", shape=(1134,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_19:0\", shape=(1134, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_23:0\", shape=(100,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_22:0\", shape=(100, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_14:0\", shape=(197,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_13:0\", shape=(197, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_17:0\", shape=(1448,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_16:0\", shape=(1448, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_20:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_19:0\", shape=(1239, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_23:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_22:0\", shape=(120, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_11:0\", shape=(197,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_10:0\", shape=(197, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_13:0\", shape=(1448,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_12:0\", shape=(1448, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_15:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_14:0\", shape=(1239, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_17:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_16:0\", shape=(120, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_14:0\", shape=(197,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_13:0\", shape=(197, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_17:0\", shape=(1448,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_16:0\", shape=(1448, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_20:0\", shape=(1239,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_19:0\", shape=(1239, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_23:0\", shape=(120,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_22:0\", shape=(120, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_31/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Reshape_20:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_conv_31/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_21/graph_pool_30/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.191\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.173, validation r2_score = -0.191, test r2_score = -0.174\n",
      "INFO:ATOM:*** Total score for epoch 1 is -0.0463, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.001, validation r2_score = -0.046, test r2_score = -0.135\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.001, validation r2_score = -0.048, test r2_score = 0.195\n",
      "INFO:ATOM:*** Total score for epoch 3 is -0.000668, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.068, validation r2_score = -0.001, test r2_score = 0.256\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.056, validation r2_score = -0.035, test r2_score = 0.052\n",
      "INFO:ATOM:*** Total score for epoch 5 is 0.0182, is new maximum\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.090, validation r2_score = 0.018, test r2_score = 0.255\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.051, validation r2_score = -0.025, test r2_score = 0.209\n",
      "INFO:ATOM:*** Total score for epoch 7 is 0.0193, is new maximum\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.103, validation r2_score = 0.019, test r2_score = 0.303\n",
      "INFO:ATOM:*** Total score for epoch 8 is 0.0381, is new maximum\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.122, validation r2_score = 0.038, test r2_score = 0.167\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.086, validation r2_score = -0.005, test r2_score = 0.224\n",
      "INFO:ATOM:Epoch 10: training r2_score = 0.135, validation r2_score = 0.009, test r2_score = 0.124\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.140, validation r2_score = 0.026, test r2_score = 0.158\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.094, validation r2_score = -0.027, test r2_score = -0.058\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.135, validation r2_score = 0.025, test r2_score = 0.071\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.136, validation r2_score = 0.003, test r2_score = -0.007\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.111, validation r2_score = -0.049, test r2_score = 0.013\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.119, validation r2_score = -0.030, test r2_score = -0.057\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.161, validation r2_score = 0.021, test r2_score = 0.116\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.107, validation r2_score = -0.046, test r2_score = 0.029\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.075, validation r2_score = -0.056, test r2_score = 0.300\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.127, validation r2_score = -0.010, test r2_score = 0.097\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.084, validation r2_score = -0.076, test r2_score = 0.166\n",
      "INFO:ATOM:Epoch 22: training r2_score = 0.081, validation r2_score = -0.068, test r2_score = 0.206\n",
      "INFO:ATOM:Epoch 23: training r2_score = 0.136, validation r2_score = -0.033, test r2_score = 0.270\n",
      "INFO:ATOM:Epoch 24: training r2_score = 0.101, validation r2_score = -0.040, test r2_score = 0.284\n",
      "INFO:ATOM:Epoch 25: training r2_score = 0.186, validation r2_score = 0.003, test r2_score = 0.253\n",
      "INFO:ATOM:Epoch 26: training r2_score = 0.157, validation r2_score = -0.020, test r2_score = 0.397\n",
      "INFO:ATOM:Epoch 27: training r2_score = 0.131, validation r2_score = -0.077, test r2_score = 0.144\n",
      "INFO:ATOM:Epoch 28: training r2_score = 0.161, validation r2_score = -0.031, test r2_score = 0.219\n",
      "INFO:ATOM:Epoch 29: training r2_score = 0.149, validation r2_score = -0.045, test r2_score = 0.131\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_wrapper.py:2540: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  chkpt_dict = yaml.load(chkpt_in.read())\n",
      "INFO:ATOM:Saved model files to '/mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1a316aff-6a7d-49ed-ad70-98d5285bf32b/best_model'\n",
      "INFO:ATOM:Best model from epoch 8 saved to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/1a316aff-6a7d-49ed-ad70-98d5285bf32b/best_model\n",
      "INFO:ATOM:Wrote model tarball to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles_model_1a316aff-6a7d-49ed-ad70-98d5285bf32b.tar.gz\n",
      "INFO:ATOM:Created a dataset hash 'a0eb2e6092b3542373f67528e299e283' from dataset_key '/mnt/projects/ATOM/sarkart4/Data/CYP2D6-ampl-1.1.0_old/cyp2d6_union_trainset_base_smiles.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 512,256,128, dropouts: 0.5,0.5,0.5, learning rate: 0.0007, valid_r2: 0.038124783993827904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ATOM:Attempting to load featurized dataset\n",
      "DEBUG:ATOM:Exception when trying to load featurized data:\n",
      "DynamicFeaturization doesn't support get_featurized_dset_name()\n",
      "INFO:ATOM:Featurized dataset not previously saved for dataset cyp2d6_union_trainset_base_smiles, creating new\n",
      "INFO:ATOM:Featurizing sample 0\n",
      "INFO:ATOM:Featurizing sample 1000\n",
      "INFO:ATOM:Featurizing sample 2000\n",
      "INFO:ATOM:Featurizing sample 3000\n",
      "INFO:ATOM:Featurizing sample 4000\n",
      "INFO:ATOM:Featurizing sample 5000\n",
      "INFO:ATOM:Featurizing sample 6000\n",
      "INFO:ATOM:Featurizing sample 7000\n",
      "INFO:ATOM:Featurizing sample 8000\n",
      "INFO:ATOM:Featurizing sample 9000\n",
      "INFO:ATOM:Featurizing sample 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ATOM:Previous dataset split restored\n",
      "INFO:ATOM:Wrote transformers to /mnt/projects/ATOM/sarkart4/Data/HPO_models_CYP2D6_old/cyp2d6_union_trainset_base_smiles/NN_graphconv_scaffold_regression/f559ad0c-a3b6-4195-a602-440e6ea855df/transformers.pkl\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "INFO:ATOM:Transforming response data\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_14:0\", shape=(179,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_13:0\", shape=(179, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_17:0\", shape=(1498,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_16:0\", shape=(1498, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_20:0\", shape=(1203,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_19:0\", shape=(1203, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_23:0\", shape=(84,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_22:0\", shape=(84, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_11:0\", shape=(179,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_10:0\", shape=(179, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_13:0\", shape=(1498,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_12:0\", shape=(1498, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_15:0\", shape=(1203,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_14:0\", shape=(1203, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_17:0\", shape=(84,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_16:0\", shape=(84, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_18:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_20:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_22:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_24:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_26:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_28:0\", shape=(0, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_14:0\", shape=(179,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_13:0\", shape=(179, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_17:0\", shape=(1498,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_16:0\", shape=(1498, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_20:0\", shape=(1203,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_19:0\", shape=(1203, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_23:0\", shape=(84,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_22:0\", shape=(84, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_14:0\", shape=(218,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_13:0\", shape=(218, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_17:0\", shape=(1504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_16:0\", shape=(1504, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_20:0\", shape=(1272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_19:0\", shape=(1272, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_23:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_22:0\", shape=(108, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_11:0\", shape=(218,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_10:0\", shape=(218, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_13:0\", shape=(1504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_12:0\", shape=(1504, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_15:0\", shape=(1272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_14:0\", shape=(1272, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_17:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_16:0\", shape=(108, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_14:0\", shape=(218,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_13:0\", shape=(218, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_17:0\", shape=(1504,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_16:0\", shape=(1504, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_20:0\", shape=(1272,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_19:0\", shape=(1272, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_23:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_22:0\", shape=(108, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_13:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_16:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_19:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_22:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_10:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_12:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_14:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_13:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_16:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_19:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_22:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_25:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Reshape_28:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_35/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Reshape_20:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_conv_35/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_25:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/sarkart4/miniconda3/envs/ampl-1.4.1/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Reshape_28:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_23/graph_pool_34/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "INFO:ATOM:Total score for epoch 0 is -0.0147\n",
      "INFO:ATOM:Epoch 0: training r2_score = -0.002, validation r2_score = -0.015, test r2_score = -0.081\n",
      "INFO:ATOM:*** Total score for epoch 1 is 0.0523, is new maximum\n",
      "INFO:ATOM:Epoch 1: training r2_score = 0.076, validation r2_score = 0.052, test r2_score = 0.160\n",
      "INFO:ATOM:Epoch 2: training r2_score = 0.001, validation r2_score = -0.043, test r2_score = 0.160\n",
      "INFO:ATOM:*** Total score for epoch 3 is 0.0668, is new maximum\n",
      "INFO:ATOM:Epoch 3: training r2_score = 0.131, validation r2_score = 0.067, test r2_score = 0.130\n",
      "INFO:ATOM:Epoch 4: training r2_score = 0.092, validation r2_score = 0.034, test r2_score = 0.148\n",
      "INFO:ATOM:Epoch 5: training r2_score = 0.142, validation r2_score = 0.034, test r2_score = 0.212\n",
      "INFO:ATOM:Epoch 6: training r2_score = 0.113, validation r2_score = 0.019, test r2_score = 0.205\n",
      "INFO:ATOM:Epoch 7: training r2_score = 0.076, validation r2_score = 0.013, test r2_score = 0.004\n",
      "INFO:ATOM:*** Total score for epoch 8 is 0.0723, is new maximum\n",
      "INFO:ATOM:Epoch 8: training r2_score = 0.155, validation r2_score = 0.072, test r2_score = 0.235\n",
      "INFO:ATOM:*** Total score for epoch 9 is 0.0831, is new maximum\n",
      "INFO:ATOM:Epoch 9: training r2_score = 0.162, validation r2_score = 0.083, test r2_score = 0.222\n",
      "INFO:ATOM:Epoch 10: training r2_score = -0.063, validation r2_score = -0.128, test r2_score = 0.175\n",
      "INFO:ATOM:*** Total score for epoch 11 is 0.0852, is new maximum\n",
      "INFO:ATOM:Epoch 11: training r2_score = 0.164, validation r2_score = 0.085, test r2_score = 0.145\n",
      "INFO:ATOM:Epoch 12: training r2_score = 0.186, validation r2_score = 0.070, test r2_score = 0.193\n",
      "INFO:ATOM:Epoch 13: training r2_score = 0.156, validation r2_score = 0.030, test r2_score = -0.097\n",
      "INFO:ATOM:Epoch 14: training r2_score = 0.193, validation r2_score = 0.069, test r2_score = 0.091\n",
      "INFO:ATOM:Epoch 15: training r2_score = 0.165, validation r2_score = 0.040, test r2_score = -0.104\n",
      "INFO:ATOM:Epoch 16: training r2_score = 0.196, validation r2_score = 0.064, test r2_score = -0.050\n",
      "INFO:ATOM:Epoch 17: training r2_score = 0.174, validation r2_score = 0.053, test r2_score = -0.067\n",
      "INFO:ATOM:Epoch 18: training r2_score = 0.007, validation r2_score = -0.107, test r2_score = 0.301\n",
      "INFO:ATOM:Epoch 19: training r2_score = 0.089, validation r2_score = -0.031, test r2_score = 0.286\n",
      "INFO:ATOM:Epoch 20: training r2_score = 0.157, validation r2_score = 0.022, test r2_score = 0.246\n",
      "INFO:ATOM:Epoch 21: training r2_score = 0.136, validation r2_score = 0.021, test r2_score = 0.216\n",
      "INFO:ATOM:Epoch 22: training r2_score = -0.002, validation r2_score = -0.102, test r2_score = 0.260\n"
     ]
    }
   ],
   "source": [
    "# (SLOW - more than 12 hours)\n",
    "layer_dropout = [\n",
    "#                 ('64,16','0.3,0.3'),\n",
    "#                 ('64,16','0.5,0.5'),\n",
    "                 #('128,32','0.0,0.0'),\n",
    "                 ('128,32','0.5,0.5'),\n",
    "                 #('256,64','0.0,0.0'),\n",
    "                 ('256,64','0.5,0.5'),\n",
    "                 #('512,128','0.0,0.0'),\n",
    "                 ('512,128','0.5,0.5'),\n",
    "                 #('256,64,16','0.0,0.0,0.0'),\n",
    "                 ('256,64,16','0.5,0.5,0.5'),\n",
    "                 #('512,256,32','0.0,0.0,0.0'),\n",
    "                 ('512,256,32','0.5,0.5,0.5'),\n",
    "                 #('512,256,128','0.0,0.0,0.0'),\n",
    "                 ('512,256,128','0.5,0.5,0.5'),\n",
    "                 ('512,128,128','0.5,0.5,0.5'),\n",
    "                 ('512,256,128,64','0.5,0.5,0.5,0.5'),\n",
    "\n",
    "]\n",
    "lr_choice = [0.0007, 0.005] # [.00001,.00005,.0001,.0005,.001,.005,.01,.05]\n",
    "\n",
    "for layers,dropouts in layer_dropout:\n",
    "    for learning_rate in lr_choice:\n",
    "        params[\"layer_sizes\"] = layers\n",
    "        params[\"dropouts\"] = dropouts\n",
    "        params[\"learning_rate\"] = learning_rate\n",
    "        tp = parse.wrapper(params)\n",
    "        pl = mp.ModelPipeline(tp)\n",
    "        pl.train_model()\n",
    "        pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
    "        pred_results = pred_data.get_prediction_results()\n",
    "        print(f\"layers: {layers}, dropouts: {dropouts}, learning rate: {learning_rate}, valid_r2: {pred_results['r2_score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - NN (submit batch jobs FRCE- Titli's code new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import parallel, delayed\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combos = [] # list of params dict: each element is a params dict with specific set of leyrs,dropouts, lr_rate combinations\n",
    "\n",
    "# layer_dropout = [\n",
    "#                 #  ('64,16','0.1,0.1'),\n",
    "#                 #  ('64,16','0.2,0.2'),\n",
    "#                  ('64,16','0.3,0.3'),\n",
    "#                  ('64,16','0.4,0.4'),\n",
    "#                  ('128,32','0.1,0.1'),\n",
    "#                  ('128,32','0.2,0.2'),\n",
    "#                  ('128,32','0.3,0.3'),\n",
    "#                  ('128,32','0.4,0.4'),\n",
    "#                  ('256,64','0.1,0.1'),\n",
    "#                  ('256,64','0.2,0.2'),\n",
    "#                  ('256,64','0.3,0.3'),\n",
    "#                  ('256,64','0.4,0.4'),\n",
    "#                  ('512,128','0.1,0.1'),\n",
    "#                  ('512,128','0.2,0.2'),\n",
    "#                  ('512,128','0.3,0.3'),\n",
    "#                  ('512,128','0.4,0.4'),\n",
    "#                  ('256,64,16','0.1,0.1,0.1'),\n",
    "#                  ('256,64,16','0.2,0.2,0.2'),\n",
    "#                  ('256,64,16','0.3,0.3,0.3'),\n",
    "#                  ('256,64,16','0.4,0.4,0.4'),\n",
    "# ]\n",
    "# lr_choice = [.00001,.00005,.0001,.0005,.001,.005,.01,.025,.05,.075]\n",
    "# def parallelrun(params):\n",
    "#     tp = parse.wrapper(params)\n",
    "#     pl = mp.ModelPipeline(tp)\n",
    "#     pl.train_model()\n",
    "#     pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
    "#     pred_results = pred_data.get_prediction_results()\n",
    "#     print(f\"layers: {layers}, dropouts: {dropouts}, learning rate: {learning_rate}, valid_r2: {pred_results['r2_score']}\\n\")\n",
    "    \n",
    "# #Parallel(n_jobs=multiprocessing.cpu_count(), verbose=50)delayed(parallelrun)(params)for combo in combos)\n",
    "param_combos=[]\n",
    "for layers,dropouts in layer_dropout:\n",
    "  for learning_rate in lr_choice:\n",
    "    params[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - xGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " 'collection_name': 'CYP2D6',\n",
    " 'dataset_key': data_file,\n",
    " 'datastore': 'False',\n",
    " 'featurizer': 'computed_descriptors',\n",
    " 'descriptor_type':'mordred_filtered',\n",
    " 'id_col': 'compound_id',\n",
    " 'lc_account': 'None',\n",
    " 'max_epochs': '100',\n",
    " 'model_type': 'xgboost',\n",
    " 'prediction_type': 'regression',\n",
    " 'previously_split': 'True',\n",
    " 'rerun': 'False',\n",
    " 'response_cols': 'pIC50',\n",
    " 'result_dir': outdir,\n",
    " 'save_results': 'False',\n",
    " 'smiles_col': 'base_rdkit_smiles',\n",
    " 'split_uuid': split_uuid,\n",
    " 'transformers': 'True',\n",
    " 'uncertainty': 'True',\n",
    " 'verbose': 'False'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96 models per feature set, ~40 seconds per model; ~1:04 hours\n",
    "gamma_choice = [4,8,16] # done [0.00,0.05, 0.1,0.2,0.3,0.4,0.5,1,2]\n",
    "lr_choice = [0.15,0.10,0.05,0.01,0.001,0.0001] # done  [0.25,0.2] \n",
    "\n",
    "for gamma in gamma_choice:\n",
    "    for learning_rate in lr_choice:\n",
    "        params[\"xgb_gamma\"] = gamma\n",
    "        params[\"xgb_learning_rate\"] = learning_rate\n",
    "        tp = parse.wrapper(params)\n",
    "        pl = mp.ModelPipeline(tp)\n",
    "        pl.train_model()\n",
    "        pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
    "        pred_results = pred_data.get_prediction_results()\n",
    "        print(f\"xgb gamma: {gamma}, xgb learning rate: {learning_rate}, valid_r2: {pred_results['r2_score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor HP search with *groupby*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = outdir+'RF_GridSearch/*'\n",
    "# ! mv $source $outdir\n",
    "# !ls $outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = cm.get_summary_perf_tables(collection_names=None, filter_dict={}, result_dir=outdir, prediction_type='regression', verbose=False)\n",
    "#perf_df = perf_df[perf_df.rf_estimators!=500]\n",
    "perf_df = perf_df.sort_values(by=\"valid_r2_score\", ascending=False)\n",
    "perf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df.groupby(by=['model_type', 'features']).count()[['model_uuid']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmods = perf_df[perf_df.model_type==\"RF\"]\n",
    "print(rfmods.shape)\n",
    "print(rfmods.head(1)['valid_r2_score'])\n",
    "rfmods.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmods = perf_df[perf_df.model_type==\"NN\"]\n",
    "print(nnmods.shape)\n",
    "print(nnmods.head(1)['valid_r2_score'])\n",
    "nnmods.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboostmods = perf_df[perf_df.model_type==\"xgboost\"]\n",
    "print(xgboostmods.shape)\n",
    "print(xgboostmods.head(1)['valid_r2_score'])\n",
    "xgboostmods.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be 10 each, 20 groups per feature, if you got all the models created\n",
    "nnmods.groupby(by=['features','layer_sizes','dropouts']).count()[['model_uuid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual of RF HPO results\n",
    "fig, ax = plt.subplots(1,3,figsize=(21,7))\n",
    "sns.boxplot(data=perf_df, x=\"rf_estimators\", y=\"valid_r2_score\", ax=ax[0])\n",
    "sns.boxplot(data=perf_df, x=\"rf_max_depth\", y=\"valid_r2_score\", ax=ax[1])\n",
    "sns.boxplot(data=perf_df, x=\"rf_max_features\", y=\"valid_r2_score\", ax=ax[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baysean optimization NN - manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "def lossfn(p):\n",
    "    params[\"learning_rate\"] = float(p[\"learn_rate\"])\n",
    "    params[\"layer_sizes\"] = int(p[\"layer_size\"])\n",
    "    params[\"layer_nums\"] = int(p[\"layer_num\"])\n",
    "    params[\"dropouts\"] = float(p[\"dropout\"])\n",
    "\n",
    "    tparam = parse.wrapper(params)\n",
    "    pl = mp.ModelPipeline(tparam)\n",
    "    pl.train_model()\n",
    "    perf_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
    "    pred_results = perf_data.get_prediction_results()\n",
    "    r2 = pred_results['r2_score']\n",
    "    return {'loss': 1-r2, \n",
    "            'status': STATUS_OK, \n",
    "            'model': tparam.model_tarball_path, \n",
    "            'model_uuid': tparam.model_uuid,\n",
    "            'learn_rate': params[\"learning_rate\"],\n",
    "            'layer_size': params[\"layer_sizes\"],\n",
    "            'layer_num': params[\"layer_nums\"],\n",
    "            'dropout': params['dropouts']}\n",
    "\n",
    "space = {\n",
    "    \"learn_rate\": hp.uniform(\"learn_rate\", 0.002, 0.006),\n",
    "    \"layer_size\": hp.uniform(\"layer_size\", 16, 256),\n",
    "    \"layer_num\": hp.uniform(\"layer_num\", 2, 4),\n",
    "    \"dropout\": hp.uniform(\"droupout\", 0.1, 0.6)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(lossfn, space, algo=tpe.suggest, max_evals=5, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list = [1-trials.trials[i][\"result\"][\"loss\"] for i in range(len(trials.trials))]\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "sns.lineplot(x=list(range(1,len(trials.trials)+1)), y=r2_list, ax=ax)\n",
    "#ax.set_ylim(0.2,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame({\"model_uuid\": model_uuid_list,\"learning_rate\": lr_list, \"layer_sizes\": ls_list, \"layer_nums\": ln_list, \"dropouts\": drop_list, \"valid_r2_score\": r2_list})\n",
    "perf_df.sort_values(by=\"valid_r2_score\", ascending=False)\n",
    "# perf_df.to_csv(file_dir + 'NN_Bayesian_Search/' + target_name + '_NN_Bayesian_Search_5_trials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Bayesian optimization trial object and continue later\n",
    "# save the trial object\n",
    "trial_file = os.path.join(\"hp_trial.pkl\")\n",
    "with open(trial_file, \"wb\") as f:\n",
    "    pickle.dump(trials, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trial object\n",
    "with open(trial_file, \"rb\") as f:\n",
    "    new_trials = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue HPO\n",
    "best = fmin(lossfn, space, algo=tpe.suggest, max_evals=50, trials=new_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list = [1-new_trials.trials[i][\"result\"][\"loss\"] for i in range(len(new_trials.trials))]\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "sns.lineplot(x=list(range(1,len(new_trials.trials)+1)), y=r2_list, ax=ax)\n",
    "#ax.set_ylim(0.2,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [trials.trials[i][\"result\"][\"learn_rate\"] for i in range(len(trials.trials))]\n",
    "ls_list = [trials.trials[i][\"result\"][\"layer_size\"] for i in range(len(trials.trials))]\n",
    "ln_list = [trials.trials[i][\"result\"][\"layer_num\"] for i in range(len(trials.trials))]\n",
    "drop_list = [trials.trials[i][\"result\"][\"dropout\"] for i in range(len(trials.trials))]\n",
    "model_uuid_list = [trials.trials[i][\"result\"][\"model_uuid\"] for i in range(len(trials.trials))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 2 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_RF.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_RF_mordred_seltrain.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_txptr_hyperopt_RF.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_scr_hyperopt_RF.json.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN computed descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 1 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_NN_3_noGC.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_NN_mordred_sel.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_NN_mordred_seltrain.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_txptr_hyperopt_NN.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_scr_hyperopt_NN.json.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 1 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_NN_3_GC.json.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_hyperopt_xg_mordred_seltrain.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_txptr_hyperopt_xg.json.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -qn 3 /g/g16/apaulson/train_JSON_FILE.DILIst_scr_hyperopt_xg.json.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "from atomsci.clients import MLMTClient\n",
    "import atomsci.ddm.pipeline.model_tracker as mt\n",
    "import atomsci.ddm.pipeline.compare_models as cmp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=MLMTClient()\n",
    "for coll in client.get_collection_names()[2:19]:\n",
    "    collections = [coll]\n",
    "    res=client.count_models(coll)\n",
    "    print(f'Num models in {coll}: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections=['DILIst_class']\n",
    "responsecols = 'DILIst_Classification'\n",
    "allmodels1=cmp.get_multitask_perf_from_tracker(collections[0], response_cols=responsecols, \n",
    "                                              expand_subsets='train,test,val', exhaustive=True)\n",
    "allmodels1=allmodels1[allmodels1.prediction_type=='classification']\n",
    "allmodels1['model_run']='No bio data'\n",
    "allmodels1=allmodels1.reset_index(drop=True)\n",
    "print(allmodels1.best_valid_roc_auc_score.max())\n",
    "print(allmodels1.shape)\n",
    "allmodels1.groupby(by=['model_type', 'features', 'best_valid_num_compounds']).count()[['model_uuid']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections=['DILIst_txptr_class']\n",
    "responsecols = 'DILIst_Classification'\n",
    "allmodels2=cmp.get_multitask_perf_from_tracker(collections[0], response_cols=responsecols, \n",
    "                                              expand_subsets='train,test,val', exhaustive=True)\n",
    "allmodels2=allmodels2[allmodels2.features.str.contains('scr')]\n",
    "allmodels2['model_run']='Scram bio data'\n",
    "allmodels2=allmodels2.reset_index(drop=True)\n",
    "print(allmodels2.best_valid_roc_auc_score.max())\n",
    "print(allmodels2.shape)\n",
    "allmodels2.groupby(by=['model_type', 'features', 'best_valid_num_compounds']).count()[['model_uuid']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections=['DILIst_txptr_class']\n",
    "responsecols = 'DILIst_Classification'\n",
    "allmodels3=cmp.get_multitask_perf_from_tracker(collections[0], response_cols=responsecols, \n",
    "                                              expand_subsets='train,test,val', exhaustive=True)\n",
    "allmodels3=allmodels3[allmodels3.prediction_type=='classification']\n",
    "allmodels3=allmodels3[allmodels3.features.str.contains('txptr')]\n",
    "allmodels3['model_run']='With bio data'\n",
    "allmodels3=allmodels3.reset_index(drop=True)\n",
    "print(allmodels3.best_valid_roc_auc_score.max())\n",
    "print(allmodels3.shape)\n",
    "allmodels3.groupby(by=['model_type', 'features', 'best_valid_num_compounds']).count()[['model_uuid']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodels=pd.concat([allmodels1, allmodels2, allmodels3])\n",
    "allmodels = allmodels[allmodels.descriptor_type!= 'mordred_sel']\n",
    "allmodels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best RF model +/- txptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='RF') & (allmodels.model_run=='Scram bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = collection = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='RF') & (allmodels.model_run=='With bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = collection = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='NN') & (allmodels.model_run=='Scram bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='NN') & (allmodels.model_run=='With bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best XG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='xgboost') & (allmodels.model_run=='Scram bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = collection = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid=allmodels[(allmodels.model_type=='xgboost') & (allmodels.model_run=='With bio data')].sort_values('best_valid_roc_auc_score', ascending=False).model_uuid.iloc[0]\n",
    "collection_name = collection = mt.get_model_collection_by_uuid(model_uuid)\n",
    "top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "model_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model#['training_metrics'][1]#['prediction_results']['r2_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict w/ best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('%s/workspace/bitbucket_repos/data_science/code' % os.environ['HOME'])\n",
    "\n",
    "from atomsci.ddm.pipeline import predict_from_model as pfm\n",
    "import plotting_functions_misc_akp as pfma\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, r2_score, precision_recall_curve, average_precision_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from sklearn 0.22.0 package\n",
    "def balanced_accuracy_score(conf_mat, *, sample_weight=None,\n",
    "                            adjusted=False):\n",
    "    \"\"\"Compute the balanced accuracy.\n",
    "    The balanced accuracy in binary and multiclass classification problems to\n",
    "    deal with imbalanced datasets. It is defined as the average of recall\n",
    "    obtained on each class.\n",
    "    The best value is 1 and the worst value is 0 when ``adjusted=False``.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        per_class = np.diag(conf_mat) / conf_mat.sum(axis=1)\n",
    "    if np.any(np.isnan(per_class)):\n",
    "        warnings.warn('y_pred contains classes not in y_true')\n",
    "        per_class = per_class[~np.isnan(per_class)]\n",
    "    score = np.mean(per_class)\n",
    "    if adjusted:\n",
    "        n_classes = len(per_class)\n",
    "        chance = 1 / n_classes\n",
    "        score -= chance\n",
    "        score /= 1 - chance\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodels['best_valid_balanced_accuracy'] = [balanced_accuracy_score(np.array(x[0])) for x in allmodels.best_valid_confusion_matrix]\n",
    "allmodels['best_test_balanced_accuracy'] = [balanced_accuracy_score(np.array(x[0])) for x in allmodels.best_test_confusion_matrix]\n",
    "allmodels['best_train_balanced_accuracy'] = [balanced_accuracy_score(np.array(x[0])) for x in allmodels.best_train_confusion_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_metric = 'best_valid_roc_auc_score'\n",
    "# selection_metric = 'best_valid_balanced_accuracy'\n",
    "# selection_metric = 'best_valid_prc_auc_score'\n",
    "# selection_metric = 'best_valid_accuracy_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best class scramble model', allmodels[allmodels.model_run=='Scram bio data'][selection_metric].max())\n",
    "print('Best classification model', allmodels[allmodels.model_run=='No bio data'][selection_metric].max())\n",
    "print('Best class+tbiodata model', allmodels[allmodels.model_run=='With bio data'][selection_metric].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model1=allmodels[allmodels.model_run=='Scram bio data'].sort_values(selection_metric, ascending=False).iloc[0]\n",
    "top_model2=allmodels[allmodels.model_run=='With bio data'].sort_values(selection_metric, ascending=False).iloc[0:10]\n",
    "# top_models=[(top_model1.model_uuid, 'best base model'), (top_model2.model_uuid, 'best +bio model')]\n",
    "top_models=top_model2.model_uuid.tolist()\n",
    "print(top_models)\n",
    "print(top_model1[selection_metric])\n",
    "print(top_model2[selection_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with the colors you want to use\n",
    "colors = [\n",
    "    \"#7682A4\",\n",
    "    \"#A7DDD8\",\n",
    "    \"#373C50\",\n",
    "    \"#694691\",\n",
    "    \"#BE2369\",\n",
    "    \"#EB1E23\",\n",
    "    \"#6EC8BE\",\n",
    "    \"#FFC30F\",\n",
    "]\n",
    "# Set your custom color palette\n",
    "pal=sns.color_palette(colors)\n",
    "sns.set_palette(pal)\n",
    "sns.palplot(pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pfma)\n",
    "import tempfile\n",
    "from atomsci.ddm.pipeline import parameter_parser as parse\n",
    "from atomsci.ddm.pipeline import model_pipeline as mp\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_style(\"white\")\n",
    "tcpl='_tcpl';adj='_adj'\n",
    "id_col='compound_id'\n",
    "smiles_col='base_rdkit_smiles'\n",
    "pos_label=1\n",
    "class_names=['DILIneg', 'DILIpos']\n",
    "\n",
    "model_label='Best bio data model'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    for model_uuid in top_models:\n",
    "\n",
    "# set variable names & get data\n",
    "        collection_name = mt.get_model_collection_by_uuid(model_uuid)\n",
    "        top_model=mt.get_full_metadata_by_uuid(model_uuid, collection_name)\n",
    "        dataset_key=top_model['training_dataset']['dataset_key']\n",
    "        dataset = dataset_key.split('/')[-1].replace('.csv','')\n",
    "        df=pd.read_csv(dataset_key, index_col=0)\n",
    "        response_cols = top_model['training_dataset']['response_cols']\n",
    "        if len(response_cols)==1: response_col=response_cols[0]\n",
    "        else: response_col=response_cols\n",
    "        featurizer= top_model['model_parameters']['featurizer']\n",
    "        cols=['compound_id', 'DILIst_Classification', 'CompoundName', 'vDILIConcern', 'SeverityClass']\n",
    "        split_uuid=top_model['splitting_parameters']['split_uuid']\n",
    "        if featurizer == 'computed_descriptors':\n",
    "            featurized = True\n",
    "            feat_type=top_model['descriptor_specific']['descriptor_type']\n",
    "            feat = pd.read_csv(f'/g/g16/apaulson/workspace/datasets/scaled_descriptors/{dataset}_with_{feat_type}_descriptors.csv')\n",
    "        else:\n",
    "            featurized = False\n",
    "            feat_type = featurizer\n",
    "            feat=df\n",
    "        feat[id_col]=feat[id_col].astype(str)\n",
    "        meta=df[cols]\n",
    "        meta[id_col]=meta[id_col].astype(str)\n",
    "        splitdf=pd.read_csv(f'/g/g16/apaulson/workspace/datasets/{dataset}_train_valid_test_scaffold_{split_uuid}.csv')\n",
    "        splitdf['cmpd_id']=splitdf['cmpd_id'].astype(str)\n",
    "        \n",
    "# list model metrics from model tracker\n",
    "        print('Training metrics from model tracker\\n\\n', top_model['training_metrics'][0]['prediction_results'], '\\n')\n",
    "        print('Validation metrics from model tracker\\n\\n', top_model['training_metrics'][1]['prediction_results'], '\\n')\n",
    "        print('Test metrics from model tracker\\n\\n', top_model['training_metrics'][2]['prediction_results'], '\\n')\n",
    "        \n",
    "# predict (either predict from model or this code snippet give same results)\n",
    "        pred_params = {\n",
    "        'featurizer': 'computed_descriptors',\n",
    "        'result_dir': tempfile.mkdtemp(),\n",
    "        'id_col': id_col,\n",
    "        'smiles_col': smiles_col,\n",
    "        'response_cols': response_cols\n",
    "        }\n",
    "        pred_params = parse.wrapper(pred_params)\n",
    "        # pipe, pparams = mp.load_from_tracker(model_uuid)\n",
    "        pipe = mp.create_prediction_pipeline(pred_params, model_uuid, collection_name)\n",
    "        if pipe.params.model_type == 'xgboost':\n",
    "            pipe.params.uncertainty = False\n",
    "        full_df = pipe.predict_full_dataset(feat, contains_responses=True, is_featurized=featurized,\n",
    "                                            dset_params=pred_params)\n",
    "#         full_df = pfm.predict_from_tracker_model(model_uuid, collection_name, feat, id_col,\n",
    "#                                                  smiles_col, response_cols,\n",
    "#                                                  is_featurized=featurized, dont_standardize=True)\n",
    "        full_df=full_df.merge(meta, how=\"inner\", on=\"compound_id\")\n",
    "        full_df=full_df.merge(splitdf, how=\"inner\", left_on=\"compound_id\", right_on=\"cmpd_id\")\n",
    "        full_df=full_df[~full_df[response_col].isna()]\n",
    "        \n",
    "# graph\n",
    "        fig, ax = plt.subplots(2,2, sharex=False, sharey=False, figsize=(20,20))\n",
    "        ax=ax.ravel()\n",
    "       \n",
    "    \n",
    "# training set    \n",
    "        pred_df=full_df[full_df.subset=='train']\n",
    "        \n",
    "    # calculate further metrics\n",
    "        print('\\nCalculated metrics from predictions')\n",
    "        \n",
    "        accscore = accuracy_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('\\ntrain accuracy', accscore)\n",
    "        \n",
    "        cm=confusion_matrix(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('train CM', cm)\n",
    "                \n",
    "        average_precision = average_precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        print('train prc_auc', average_precision)\n",
    "        \n",
    "        prescore = precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"train precision\", prescore)\n",
    "        \n",
    "        recscore =    recall_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"train recall\", recscore)\n",
    "\n",
    "        roc_auc = roc_auc_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"train roc_auc\", roc_auc, '\\n')\n",
    "    # plot curve\n",
    "        fpr, tpr, _ = roc_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        lw = 2\n",
    "        ax[0].plot(fpr, tpr, lw=lw, label='Train ROC curve (area = %0.2f)' % roc_auc, color = pal[3])\n",
    "    # prc \n",
    "        precision, recall, _ = precision_recall_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        line_kwargs = {\"drawstyle\": \"steps-post\"}\n",
    "        line_kwargs[\"label\"] = (f\"AP = \"\n",
    "                                f\"{average_precision:0.2f}\")\n",
    "        ax[1].plot(recall, precision, color=pal[3], **line_kwargs) \n",
    "        \n",
    "# validation set\n",
    "        pred_df=full_df[full_df.subset=='valid']\n",
    "    \n",
    "    # calculate further metrics\n",
    "        accscore = accuracy_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('valid accuracy', accscore)\n",
    "        \n",
    "        cm=confusion_matrix(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('valid CM', cm)\n",
    "        \n",
    "        average_precision = average_precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        print('valid prc_auc', average_precision)\n",
    "        \n",
    "        prescore = precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"valid precision\", prescore)\n",
    "        \n",
    "        recscore =    recall_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"valid recall\", recscore)\n",
    "        \n",
    "        roc_auc = roc_auc_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"valid roc_auc\", roc_auc, '\\n')\n",
    "        \n",
    "    # ROC AUC curve\n",
    "        fpr, tpr, _ = roc_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        lw = 2\n",
    "        line_kwargs = {\"drawstyle\": \"steps-post\"}\n",
    "        ax[0].plot(fpr, tpr, lw=lw, label='Valid ROC curve (area = %0.2f)' % roc_auc, color = pal[4], **line_kwargs)\n",
    "#         ax[0].plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
    "#         ax[0].set_xlim([0.0, 1.0])\n",
    "#         ax[0].set_ylim([0.0, 1.05])\n",
    "#         ax[0].set_xlabel('False Positive Rate')\n",
    "#         ax[0].set_ylabel('True Positive Rate')\n",
    "#         ax[0].legend(loc=\"lower right\")\n",
    "        \n",
    "    # PR curve\n",
    "        precision, recall, _ = precision_recall_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        line_kwargs = {\"drawstyle\": \"steps-post\"}\n",
    "        line_kwargs[\"label\"] = (f\"AP = \"\n",
    "                                f\"{average_precision:0.2f}\")\n",
    "        ax[1].plot(recall, precision, color=pal[4], **line_kwargs)\n",
    "#         info_pos_label = (f\" (Positive label: {pos_label})\")\n",
    "#         xlabel = \"Recall\" + info_pos_label\n",
    "#         ylabel = \"Precision\" + info_pos_label\n",
    "#         ax[1].set(xlabel=xlabel, ylabel=ylabel)\n",
    "#         ax[1].set_ylim([-0.05, 1.05])\n",
    "#         ax[1].set_ylim([-0.05, 1.05])\n",
    "#         ax[1].legend(loc=\"upper right\")\n",
    "#         ax[1].set_title(f'{dataset} {model_label} validation set\\n{model_uuid}')\n",
    "        \n",
    "    # confusion matrix - valid set (recalculated, not from table)\n",
    "        cm=confusion_matrix(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('Valid balanced accuracy\\n', balanced_accuracy_score(cm))\n",
    "        # cm=np.array(top_model['training_metrics'][1]['prediction_results']['confusion_matrix'][0])\n",
    "        im = pfma.plot_confusion_matrix(cm, classes=class_names, normalize=False, cmap=sns.cubehelix_palette(rot=0, start=2.40, as_cmap=True), ax=ax[2])\n",
    "        fig.colorbar(mappable=im, ax=ax[2], shrink=0.7)\n",
    "        ax[2].set_title(\"Valid CM\")\n",
    "        \n",
    "        \n",
    "# test set    \n",
    "        pred_df=full_df[full_df.subset=='test']\n",
    "    \n",
    "    # calculate further metrics\n",
    "        accscore = accuracy_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('test accuracy', accscore)\n",
    "        \n",
    "        cm=confusion_matrix(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('test CM', cm)\n",
    "        \n",
    "        average_precision = average_precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        print('test prc_auc', average_precision) \n",
    "        \n",
    "        prescore = precision_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"test precision\", prescore)\n",
    "        \n",
    "        recscore =    recall_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"test recall\", recscore)\n",
    "        \n",
    "        roc_auc = roc_auc_score(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print(\"test roc_auc\", roc_auc, '\\n')\n",
    "        \n",
    "    # ROC AUC curve\n",
    "        fpr, tpr, _ = roc_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        lw = 2\n",
    "        line_kwargs = {\"drawstyle\": \"steps-post\"}\n",
    "        ax[0].plot(fpr, tpr, lw=lw, label='Test ROC curve (area = %0.2f)' % roc_auc, color = pal[5], **line_kwargs)\n",
    "        ax[0].plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
    "        ax[0].set_xlim([-0.05, 1.05])\n",
    "        ax[0].set_ylim([-0.05, 1.05])\n",
    "        ax[0].set_xlabel('False Positive Rate')\n",
    "        ax[0].set_ylabel('True Positive Rate')\n",
    "        ax[0].legend(loc=\"lower right\")\n",
    "        \n",
    "    # PR curve\n",
    "        precision, recall, _ = precision_recall_curve(pred_df[f'{response_col}'], pred_df[f'{response_col}_prob'])\n",
    "        line_kwargs = {\"drawstyle\": \"steps-post\"}\n",
    "        line_kwargs[\"label\"] = (f\"AP = \"\n",
    "                                f\"{average_precision:0.2f}\")\n",
    "        ax[1].plot(recall, precision, color=pal[5], **line_kwargs)\n",
    "        info_pos_label = (f\" (Positive label: {pos_label})\")\n",
    "        xlabel = \"Recall\" + info_pos_label\n",
    "        ylabel = \"Precision\" + info_pos_label\n",
    "        ax[1].set(xlabel=xlabel, ylabel=ylabel)\n",
    "        ax[1].set_xlim([-0.05, 1.05])\n",
    "        ax[1].set_ylim([-0.05, 1.05])\n",
    "        ax[1].legend(loc=\"lower right\")\n",
    "#         ax[1].set_title(f'{dataset} {model_label} test set\\n{model_uuid}')\n",
    "        \n",
    "    # confusion matrix - test set  (recalculated, not from table)\n",
    "        cm=confusion_matrix(pred_df[f'{response_col}'], pred_df[f'{response_col}_pred'])\n",
    "        print('Test balanced accuracy\\n', balanced_accuracy_score(cm))\n",
    "        # cm=np.array(top_model['training_metrics'][2]['prediction_results']['confusion_matrix'][0])\n",
    "        im=pfma.plot_confusion_matrix(cm, classes=class_names, normalize=False, cmap=sns.cubehelix_palette(rot=0, start=2.40, as_cmap=True), ax=ax[3])\n",
    "        fig.colorbar(mappable=im, ax=ax[3], shrink=0.7)\n",
    "        ax[3].set_title(\"Train CM\")\n",
    "#         plt.tight_layout()\n",
    "        fig.suptitle(f'{dataset} {model_label}')#\\n{model_uuid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe=mp.retrain_model('a7e54dec-a8aa-4d6d-a875-b15d29e464e7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import atomsci.ddm.pipeline.perf_plots as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.plot_ROC_curve(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examine hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoretype = 'balanced_accuracy'\n",
    "winnertype= f'best_valid_{scoretype}'\n",
    "\n",
    "perf_track_df=allmodels.sort_values(by=winnertype, ascending=False)\n",
    "\n",
    "if (sum(~perf_track_df.dropouts.isna())>0):\n",
    "    perf_track_df[['drop1', 'drop2', 'drop3']] = perf_track_df.dropouts.astype(str).str.strip('[]').str.split(pat=',',n=3, expand=True).astype(float)\n",
    "    perf_track_df['layer_sizes'] = perf_track_df.layer_sizes.astype(str).str.strip('[]')\n",
    "    perf_track_df[['layer1','layer2','layer3']]=perf_track_df.layer_sizes.str.split(pat=',', n=3, expand=True).astype(float)\n",
    "    perf_track_df['num_layers'] = 3-perf_track_df[['layer1','layer2','layer3']].isna().sum(axis=1)\n",
    "    perf_track_df[['layer1','layer2','layer3']]=perf_track_df[['layer1','layer2','layer3']].fillna(value=1).astype(int)\n",
    "    perf_track_df['num_nodes']=perf_track_df.layer1 * perf_track_df.layer2 * perf_track_df.layer3\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'layer_sizes']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'num_layers']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'num_nodes']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'drop1']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'drop2']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'drop3']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'layer1']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'layer2']=np.nan\n",
    "    perf_track_df.loc[perf_track_df.model_type != \"NN\", 'layer3']=np.nan\n",
    "\n",
    "print(perf_track_df.shape)\n",
    "# print(perf_track_df.columns)\n",
    "\n",
    "print('top bal acc score:', perf_track_df[f'{winnertype}'].max().round(4))\n",
    "\n",
    "scoretype = 'roc_auc_score'\n",
    "winnertype= f'best_valid_{scoretype}'\n",
    "print('top roc score:', perf_track_df[f'{winnertype}'].max().round(4))\n",
    "\n",
    "scoretype = 'prc_auc_score'\n",
    "winnertype= f'best_valid_{scoretype}'\n",
    "print('top prc score:', perf_track_df[f'{winnertype}'].max().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = ['features', 'model_type', 'learning_rate','layer1', 'layer2', 'layer3', 'drop1', 'drop2', 'drop3',  'rf_estimators', 'rf_max_depth', 'rf_max_features','xgb_learning_rate', 'xgb_gamma', 'num_nodes', ]\n",
    "loghps=['learning_rate', 'xgb_learning_rate']\n",
    "len(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,3,figsize=(30,20))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    plot = perf_track_df[hyperparams[i]]\n",
    "    if isinstance(plot.iloc[0], str):\n",
    "        g=sns.countplot(plot, ax=ax)\n",
    "        if hyperparams[i]=='features':\n",
    "            g.set_xticklabels(g.get_xticklabels(), rotation=20, ha='right')\n",
    "    elif hyperparams[i] in loghps:\n",
    "        sns.distplot(plot, hist_kws={'log':True}, ax=ax)\n",
    "    else:\n",
    "        sns.distplot(plot, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_metric = 'best_valid_roc_auc_score'\n",
    "perf_track_df['txptr_features']=perf_track_df['features'].str.replace('_txptr', '').str.replace('_scr','')\n",
    "perf_track_df=perf_track_df.sort_values(['model_run','features'])\n",
    "plot_df=perf_track_df[(perf_track_df.txptr_features!='ecfp')&(perf_track_df.txptr_features!='graphconv')&(perf_track_df.model_run!='No bio data')]#&(perf_track_df.txptr_features!='mordred_seltrain')]\n",
    "sns.set_style(\"ticks\")\n",
    "sns.catplot(x=\"txptr_features\", y=selection_metric, \n",
    "            hue='model_run', height = 10, aspect=1, \n",
    "            kind = 'box',  showfliers = False,\n",
    "            #col='model_type',\n",
    "            data=plot_df);\n",
    "\n",
    "plot_df=plot_df.reset_index(drop=True)\n",
    "print(plot_df.shape)\n",
    "scores = plot_df.pivot(columns='features', values=selection_metric)\n",
    "print(scores.shape)\n",
    "print(scores.max())\n",
    "print(\"MOE\",ttest_ind(scores.moe_scr, scores.moe_txptr, nan_policy='omit'))\n",
    "print(\"MRS\",ttest_ind(scores.mordred_filtered_scr, scores.mordred_filtered_txptr, nan_policy='omit'))\n",
    "print(\"MRF\",ttest_ind(scores.mordred_seltrain_scr, scores.mordred_seltrain_txptr, nan_policy='omit'))\n",
    "print(\"RDK\",ttest_ind(scores.rdkit_raw_scr, scores.rdkit_raw_txptr, nan_policy='omit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoretype='balanced_accuracy'\n",
    "subset='best_valid'\n",
    "winnertype= f'{subset}_{scoretype}'\n",
    "plot_df=perf_track_df#[perf_track_df.descriptor_type=='mordred_seltrain']\n",
    "plot_df=plot_df[[f\"best_train_{scoretype}\",f\"best_valid_{scoretype}\",f\"best_test_{scoretype}\"]]\n",
    "# turn off sorting if you have a ton of models.. slow\n",
    "plot_df=plot_df.sort_values(f\"best_test_{scoretype}\")\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(26,8))\n",
    "sns.kdeplot(perf_track_df[f'best_train_{scoretype}'], label=\"train\",ax=ax[0])\n",
    "sns.kdeplot(perf_track_df[f'best_valid_{scoretype}'], label=\"valid\",ax=ax[0])\n",
    "sns.kdeplot(perf_track_df[f'best_test_{scoretype}'], label=\"test\",ax=ax[0])\n",
    "\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[1].plot(plot_df.T);\n",
    "ax[1].set_xticklabels(['train','valid','test'])\n",
    "ax[1].set_ylim(plot_df.min().min()-.1,1)\n",
    "fig.suptitle(f\"{scoretype} for DILIst classification models\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin each hp for downstream viz\n",
    "pd.set_option('display.float_format', '{:.2g}'.format)\n",
    "# hyperparams.append('best_valid_balanced_accuracy')\n",
    "hpbins =      [10,10,10,10,10,10,10,10,10,10,5,5,10,10]\n",
    "\n",
    "for i, hp in enumerate(hyperparams[2:]):\n",
    "    perf_track_df[['binned_'+hp+'_0', 'binned_'+hp]] = pd.cut(perf_track_df[hp], hpbins[i], precision=2).astype(str).str.strip('(]').str.split(',', expand=True)\n",
    "    perf_track_df=perf_track_df.drop('binned_'+hp+'_0', axis='columns')\n",
    "    perf_track_df['binned_'+hp] = perf_track_df['binned_'+hp].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_track_df.binned_num_nodes=perf_track_df.binned_num_nodes.astype(float)\n",
    "# perf_track_df.binned_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='DILIst Classification'\n",
    "if sum(~perf_track_df.rf_estimators.isna())>0:\n",
    "    feat1 = 'binned_rf_estimators'; feat2 = 'binned_rf_max_depth'; feat3 = 'binned_rf_max_features'\n",
    "    hue=feat3\n",
    "    plot_df=perf_track_df[perf_track_df.model_type=='RF']\n",
    "    plot_df = plot_df.sort_values([feat3, feat1, feat2])\n",
    "    plot_df[f'{feat1}/{feat2}'] = ['%s / %s' % (mf,est) for mf,est in zip(plot_df[feat1], plot_df[feat2])]\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        fig = plt.figure(figsize=(80,15))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        sns.scatterplot(x=f'{feat1}/{feat2}', y='{0}_{1}'.format(subset, scoretype), hue=hue, palette=sns.cubehelix_palette(len(plot_df[hue].unique())), data=plot_df, ax=ax1)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.title(f'%s RF model performance' % dataset_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(~perf_track_df.dropouts.isna())>0:\n",
    "    feat1 = 'binned_learning_rate'; feat3 = 'binned_drop1'; feat2 = 'binned_layer1'\n",
    "    hue=feat3\n",
    "    plot_df=perf_track_df[perf_track_df.model_type=='NN']\n",
    "    plot_df = plot_df.sort_values([feat3, feat1, feat2])\n",
    "    plot_df[f'{feat1}/{feat2}'] = ['%s / %s' % (mf,est) for mf,est in zip(plot_df[feat1], plot_df[feat2])]\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        fig = plt.figure(figsize=(80,15))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        sns.scatterplot(x=f'{feat1}/{feat2}', y='{0}_{1}'.format(subset, scoretype), hue=hue, palette=sns.cubehelix_palette(len(plot_df[hue].unique())), data=plot_df, ax=ax1)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.title(f'%s NN model performance - layer 1' % dataset_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(~perf_track_df.dropouts.isna())>0:\n",
    "    feat1 = 'binned_learning_rate'; feat3 = 'binned_drop2'; feat2 = 'binned_layer2'\n",
    "    hue=feat3\n",
    "    plot_df=perf_track_df[perf_track_df.model_type=='NN']\n",
    "    plot_df = plot_df.sort_values([feat3, feat1, feat2])\n",
    "    plot_df[f'{feat1}/{feat2}'] = ['%s / %s' % (mf,est) for mf,est in zip(plot_df[feat1], plot_df[feat2])]\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        fig = plt.figure(figsize=(80,15))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        sns.scatterplot(x=f'{feat1}/{feat2}', y='{0}_{1}'.format(subset, scoretype), hue=hue, palette=sns.cubehelix_palette(len(plot_df[hue].unique())), data=plot_df, ax=ax1)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.title(f'%s NN model performance - layer 2' % dataset_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(~perf_track_df.dropouts.isna())>0:\n",
    "    feat1 = 'binned_learning_rate'; feat3 = 'binned_drop3'; feat2 = 'binned_layer3'\n",
    "    hue=feat3\n",
    "    plot_df=perf_track_df[perf_track_df.model_type=='NN']\n",
    "    plot_df = plot_df.sort_values([feat3, feat1, feat2])\n",
    "    plot_df[f'{feat1}/{feat2}'] = ['%s / %s' % (mf,est) for mf,est in zip(plot_df[feat1], plot_df[feat2])]\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        fig = plt.figure(figsize=(80,15))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        sns.scatterplot(x=f'{feat1}/{feat2}', y='{0}_{1}'.format(subset, scoretype), hue=hue, palette=sns.cubehelix_palette(len(plot_df[hue].unique())-1), data=plot_df, ax=ax1)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.title(f'%s NN model performance - layer 3' % dataset_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(~perf_track_df.xgb_gamma.isna())>0:\n",
    "    feat2 = 'binned_xgb_learning_rate'; feat1 = 'xgb_gamma'\n",
    "    hue=feat2\n",
    "    plot_df=perf_track_df[perf_track_df.model_type=='xgboost']\n",
    "    plot_df = plot_df.sort_values([feat1, feat2])\n",
    "    #plot_df[f'{feat1}/{feat2}'] = ['%s / %s' % (mf,est) for mf,est in zip(plot_df[feat1], plot_df[feat2])]\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        fig = plt.figure(figsize=(40,15))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        sns.scatterplot(x=feat1, y='{0}_{1}'.format(subset, scoretype), \n",
    "                        hue=hue, palette=sns.cubehelix_palette(len(plot_df[hue].unique())), \n",
    "                        data=plot_df, ax=ax1)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.xticks(rotation=30, ha='center')\n",
    "        plt.title(f'%s XGboost model performance' % dataset_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeats=3; scoretype='balanced_accuracy'; winnertype='best_valid_balanced_accuracy'\n",
    "feat1='binned_drop1'; feat2='binned_learning_rate'; feat3='binned_num_nodes'; feat4='binned_layer1'\n",
    "feat5='binned_rf_max_depth'; feat6='binned_rf_max_features'; feat7='binned_rf_estimators'; \n",
    "feat8='binned_xgb_gamma'; feat9='binned_xgb_learning_rate'; feat12='best_test_balanced_accuracy'\n",
    "feat10='features'; feat11='model_type'; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "bnnlabs = perf_track_df.binned_num_nodes.sort_values(ascending=True).unique().tolist()\n",
    "bnnlabs.pop(-1) #remove nan - comment out if only NN models in df\n",
    "bnnlabs = [round(x, 3 - int(math.floor(math.log10(abs(x)))) - 1) for x in bnnlabs]\n",
    "bnnlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax[0,0].ticklabel_format(style='sci', scilimits=(0,0)); \n",
    "sns.set_context('poster')\n",
    "plotdf2=perf_track_df\n",
    "fig, ax = plt.subplots(3,4, figsize=(60,40))\n",
    "if sum(~perf_track_df.dropouts.isna())>0:\n",
    "    sns.boxplot(x=feat1, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat1].unique()), rot=0, start=0.60), data=plotdf2, ax=ax[0,0]); ax[0,0].tick_params(rotation=0); ax[0,0].set_xlabel('NN dropouts layer 1')\n",
    "    sns.boxplot(x=feat2, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat2].unique()), rot=0, start=0.60), data=plotdf2, ax=ax[0,1]); ax[0,1].tick_params(rotation=0); ax[0,1].set_xlabel('NN learning rate')#ax[0,1].legend_.remove(); ax[0,1].title.set_text(f\"Hyperparameters colored by {feat1}\")\n",
    "    sns.boxplot(x=feat3, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat3].unique()), rot=0, start=0.60), data=plotdf2, ax=ax[0,2]); ax[0,2].tick_params(rotation=15);ax[0,2].set_xlabel('NN number of parameters in hidden layers'); ax[0,2].set_xticklabels(bnnlabs); #ax[0,2].legend_.remove()#(bbox_to_anchor=(1,1), title=feat1)#, prop={'size': 12})\n",
    "    sns.boxplot(x=feat4, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat4].unique()), rot=0, start=0.60), data=plotdf2, ax=ax[0,3]); ax[0,3].tick_params(rotation=0); ax[0,3].set_xlabel('NN params layer 1')#ax[1,0].legend_.remove(); ax[1,0].tick_params(rotation=45)\n",
    "if sum(~perf_track_df.rf_estimators.isna())>0:\n",
    "    sns.boxplot(x=feat5, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat5].unique()), rot=0, start=2.00), data=plotdf2, ax=ax[1,0]); ax[1,0].tick_params(rotation=0); ax[1,0].set_xlabel('RF max depth')#ax[1,1].title.set_text(f\"Hyperparameters colored by {feat2}\")\n",
    "    sns.boxplot(x=feat6, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat6].unique()), rot=0, start=2.00), data=plotdf2, ax=ax[1,1]); ax[1,1].tick_params(rotation=0); ax[1,1].set_xlabel('RF max features per node')#ax[1,2].legend_.remove()#(bbox_to_anchor=(1,1), title=feat2)\n",
    "    sns.boxplot(x=feat7, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat7].unique()), rot=0, start=2.00), data=plotdf2, ax=ax[1,2]); ax[1,2].tick_params(rotation=0); ax[1,2].set_xlabel('RF number of trees')#ax[2,0].legend_.remove(); ax[2,0].tick_params(rotation=45)\n",
    "sns.scatterplot(x=feat12,y=winnertype, color=pal,                                                                      data=plotdf2, ax=ax[1,3]); ax[1,3].tick_params(rotation=0); ax[1,3].set_xlabel(f'{feat12}')#ax[2,1].legend_.remove(); ax[2,1].title.set_text(f\"Hyperparameters colored by {feat3}\")\n",
    "if sum(~perf_track_df.xgb_gamma.isna())>0:\n",
    "    sns.boxplot(x=feat8, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat8].unique()), rot=0, start=2.40), data=plotdf2, ax=ax[2,0]); ax[2,0].tick_params(rotation=0); ax[2,0].set_xlabel('XGBoost gamma')#ax[2,2].legend(bbox_to_anchor=(1,1), title=feat3);\n",
    "    sns.boxplot(x=feat9, y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat9].unique()), rot=0, start=2.40), data=plotdf2, ax=ax[2,1]); ax[2,1].tick_params(rotation=0); ax[2,1].set_xlabel('XGBoost learning rate')#ax[2,0].legend_.remove(); ax[2,0].tick_params(rotation=45)\n",
    "sns.boxplot(    x=feat10,y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat10].unique()),rot=0, start=0.10), data=plotdf2, ax=ax[2,2]); ax[2,2].tick_params(rotation=30);ax[2,2].set_xlabel('Featurization type')#ax[2,1].legend_.remove(); ax[2,1].title.set_text(f\"Hyperparameters colored by {feat3}\")\n",
    "sns.boxplot(    x=feat11,y=winnertype, palette=sns.cubehelix_palette(len(plotdf2[feat11].unique()),rot=0, start=0.10), data=plotdf2, ax=ax[2,3]); ax[2,3].tick_params(rotation=0); ax[2,3].set_xlabel('Model type');#ax[2,2].legend(bbox_to_anchor=(1,1), title=feat3);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ampl-1.4.1",
   "language": "python",
   "name": "ampl-1.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
